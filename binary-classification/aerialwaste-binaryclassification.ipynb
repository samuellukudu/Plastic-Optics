{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8370534,"sourceType":"datasetVersion","datasetId":4976188}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Binary classification","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!wget https://zenodo.org/records/7991872/files/testing.json -O testing.json\n!wget https://zenodo.org/records/7991872/files/training.json -O training.json","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:47:10.229429Z","iopub.execute_input":"2024-05-19T03:47:10.230047Z","iopub.status.idle":"2024-05-19T03:47:12.897563Z","shell.execute_reply.started":"2024-05-19T03:47:10.230018Z","shell.execute_reply":"2024-05-19T03:47:12.896409Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2024-05-19 03:47:11--  https://zenodo.org/records/7991872/files/testing.json\nResolving zenodo.org (zenodo.org)... 188.184.103.159, 188.185.79.172, 188.184.98.238, ...\nConnecting to zenodo.org (zenodo.org)|188.184.103.159|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1696233 (1.6M) [text/plain]\nSaving to: 'testing.json'\n\ntesting.json        100%[===================>]   1.62M  --.-KB/s    in 0.1s    \n\n2024-05-19 03:47:11 (13.2 MB/s) - 'testing.json' saved [1696233/1696233]\n\n--2024-05-19 03:47:12--  https://zenodo.org/records/7991872/files/training.json\nResolving zenodo.org (zenodo.org)... 188.184.103.159, 188.184.98.238, 188.185.79.172, ...\nConnecting to zenodo.org (zenodo.org)|188.184.103.159|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3142168 (3.0M) [text/plain]\nSaving to: 'training.json'\n\ntraining.json       100%[===================>]   3.00M  19.3MB/s    in 0.2s    \n\n2024-05-19 03:47:12 (19.3 MB/s) - 'training.json' saved [3142168/3142168]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -qU wandb\n!pip install -q torchsampler\n!pip install -qU torchmetrics","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:47:12.899927Z","iopub.execute_input":"2024-05-19T03:47:12.900971Z","iopub.status.idle":"2024-05-19T03:47:56.807217Z","shell.execute_reply.started":"2024-05-19T03:47:12.900906Z","shell.execute_reply":"2024-05-19T03:47:56.806116Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os, gc, sys, yaml, json, copy\nfrom pathlib import Path\nimport glob\nfrom collections import Counter, defaultdict\nfrom tqdm.auto import tqdm\n\nimport math\nimport random\nimport numpy as np\nimport pandas as pd\n\nimport cv2\nimport PIL\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import model_selection\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import utils\nfrom torchvision import transforms as T\n\nimport timm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nimport torchmetrics\nfrom torchsampler import ImbalancedDatasetSampler\n\nfrom IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:47:56.808739Z","iopub.execute_input":"2024-05-19T03:47:56.809045Z","iopub.status.idle":"2024-05-19T03:48:08.866081Z","shell.execute_reply.started":"2024-05-19T03:47:56.809016Z","shell.execute_reply":"2024-05-19T03:48:08.865268Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import wandb\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"WANDB_API_KEY\")\nwandb.login(key=secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:08.868791Z","iopub.execute_input":"2024-05-19T03:48:08.869709Z","iopub.status.idle":"2024-05-19T03:48:11.405001Z","shell.execute_reply.started":"2024-05-19T03:48:08.869671Z","shell.execute_reply":"2024-05-19T03:48:11.404039Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"CONFIG = dict(\n    img_size = [384, 384],\n    batch_size = 32,\n    epochs = 50,\n    seed = 2024\n)\n\ndef seeding(SEED):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    torch.manual_seed(SEED)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(SEED)\n        torch.cuda.manual_seed_all(SEED)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n#     os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n#     tf.random.set_seed(SEED)\n#     keras.utils.set_random_seed(seed=SEED)\n    print('seeding done!!!')\n\ndef flush():\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.reset_peak_memory_stats()\n\nseeding(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:11.406395Z","iopub.execute_input":"2024-05-19T03:48:11.407024Z","iopub.status.idle":"2024-05-19T03:48:11.439688Z","shell.execute_reply.started":"2024-05-19T03:48:11.406990Z","shell.execute_reply":"2024-05-19T03:48:11.438719Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"seeding done!!!\n","output_type":"stream"}]},{"cell_type":"code","source":"DATA_DIR = Path(\"/kaggle/input/aerial-dataset\")\nIMAGE_PATHS = glob.glob(\"/kaggle/input/aerial-dataset/*/*.png\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:11.441058Z","iopub.execute_input":"2024-05-19T03:48:11.441443Z","iopub.status.idle":"2024-05-19T03:48:14.500809Z","shell.execute_reply.started":"2024-05-19T03:48:11.441409Z","shell.execute_reply":"2024-05-19T03:48:14.499922Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"image_df = pd.DataFrame(IMAGE_PATHS, columns=['image_path'])\n\ncheck_path = lambda path: os.path.exists(path)\nget_image_dir = lambda path: int(Path(path).stem)\nimage_df['image_id'] = image_df['image_path'].map(get_image_dir)\nimage_df['exists'] = image_df['image_path'].map(check_path)\nimage_df['exists'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:14.501879Z","iopub.execute_input":"2024-05-19T03:48:14.502154Z","iopub.status.idle":"2024-05-19T03:48:31.651257Z","shell.execute_reply.started":"2024-05-19T03:48:14.502129Z","shell.execute_reply":"2024-05-19T03:48:31.650384Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"exists\nTrue    10977\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"with open(\"/kaggle/working/training.json\", \"r\") as f:\n    data = json.loads(f.read())","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:31.652695Z","iopub.execute_input":"2024-05-19T03:48:31.653132Z","iopub.status.idle":"2024-05-19T03:48:31.704859Z","shell.execute_reply.started":"2024-05-19T03:48:31.653096Z","shell.execute_reply":"2024-05-19T03:48:31.704019Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = pd.json_normalize(data, record_path=['images'])\ndf.rename(columns={'id': 'image_id'}, inplace=True)\ndf = df.merge(image_df, how='left', on='image_id')\ndf.rename(columns={'is_candidate_location': 'label'}, inplace=True)\n\n# CONFIG = len(df['label'].unique())","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:31.705981Z","iopub.execute_input":"2024-05-19T03:48:31.706269Z","iopub.status.idle":"2024-05-19T03:48:32.261829Z","shell.execute_reply.started":"2024-05-19T03:48:31.706244Z","shell.execute_reply":"2024-05-19T03:48:32.260964Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# # Assuming 'df' is your DataFrame and 'is_candidate_location' is the column of interest\n# data = df['label'].value_counts()\n\n# # Calculate percentages\n# percentages = data / data.sum() * 100\n\n# # Define the separation of sectors\n# explode = [0.1] * len(data)  # This will separate all sectors slightly. Adjust as needed.\n\n# # Create the pie chart\n# plt.figure(figsize=(10, 5))\n# plt.pie(data, labels=data.index, autopct='%1.1f%%', startangle=140, explode=explode)\n\n# # Equal aspect ratio ensures that pie is drawn as a circle.\n# plt.axis('equal')  \n# plt.title(\"Distribution of Landfill Candidate Location in Data\")\n\n# # Save the figure\n# # plt.savefig(\"landfill_distribution_pie.png\")\n\n# # Show the plot\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:32.265818Z","iopub.execute_input":"2024-05-19T03:48:32.266677Z","iopub.status.idle":"2024-05-19T03:48:32.271230Z","shell.execute_reply.started":"2024-05-19T03:48:32.266637Z","shell.execute_reply":"2024-05-19T03:48:32.270380Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class AerialDataset(utils.data.Dataset):\n    \n    def __init__(self, data, transform, mode='train'):\n        super().__init__()\n        self.data = data\n        self.tsfm = transform\n        self.mode = mode\n        self.label = data.loc[:, 'label']\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img_path = self.data.loc[idx, 'image_path']\n        target = self.data.loc[idx, 'label']\n        \n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = self.tsfm(image=image)['image']\n        \n        return {\"image\": image, \n                \"target\": torch.tensor(target, dtype=torch.float)\n               }\n    \n    def get_labels(self):\n        return self.label","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:32.272904Z","iopub.execute_input":"2024-05-19T03:48:32.273294Z","iopub.status.idle":"2024-05-19T03:48:32.286054Z","shell.execute_reply.started":"2024-05-19T03:48:32.273258Z","shell.execute_reply":"2024-05-19T03:48:32.285119Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# ts = A.Compose([\n#     A.Resize(height=512, width=512),\n#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n#     ToTensorV2()\n# ])\n\n# ds = AerialDataset(data=df, transform=ts)\n# dls = utils.data.DataLoader(ds, batch_size=8, shuffle=True, num_workers=os.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:32.287408Z","iopub.execute_input":"2024-05-19T03:48:32.287985Z","iopub.status.idle":"2024-05-19T03:48:32.295429Z","shell.execute_reply.started":"2024-05-19T03:48:32.287953Z","shell.execute_reply":"2024-05-19T03:48:32.294538Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# def get_transforms(height, width):\n#     train_tsfm = A.Compose([\n#         A.Resize(height=height, width=width),\n# #         A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.5),\n# #         A.RGBShift(r_shift_limit=25, g_shift_limit=25, b_shift_limit=25, p=0.5),\n        \n# #         A.OneOf([\n# #             A.RandomRain(brightness_coefficient=0.9, drop_width=1, blur_value=5, p=1),\n# #             A.RandomSnow(brightness_coeff=2.5, snow_point_lower=0.3, snow_point_upper=0.5, p=1),\n# #             A.RandomFog(fog_coef_lower=0.7, fog_coef_upper=0.8, alpha_coef=0.1, p=1),\n# #         ], p=0.3),\n        \n# #         A.OneOf([\n# #             A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), angle_lower=0.5, p=1),\n# #             A.RandomShadow(num_shadows_lower=1, num_shadows_upper=1, shadow_dimension=5, shadow_roi=(0, 0.5, 1, 1), p=1),\n# #         ], p=0.2),\n        \n#         A.Normalize(mean=[0.485, 0.456, 0.406],\n#                    std=[0.229, 0.224, 0.225]),\n#         ToTensorV2()\n#     ])\n    \n#     valid_tsfm = A.Compose([\n#         A.Resize(height=height, width=width),\n#         A.Normalize(mean=[0.485, 0.456, 0.406],\n#                    std=[0.229, 0.224, 0.225]),\n#         ToTensorV2()\n#     ])\n#     return {\"train\": train_tsfm, \"eval\": valid_tsfm}\n\n\ndef get_transforms(height, width):\n    train_tsfm = A.Compose([\n        # Geometric augmentations\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.RandomRotate90(p=0.5),\n        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.5),\n        # Photometric augmentations\n        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n        A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n        # cutout\n#         A.Cutout(max_h_size=int(height*0.2), max_w_size=int(width*0.2), num_holes=1, p=0.2),\n        A.Resize(height=height, width=width),\n        # Normalization and conversion to tensor\n        A.Normalize(mean=[0.485, 0.456, 0.406], \n                    std=[0.229, 0.224, 0.225]),\n        ToTensorV2()\n    ])\n    \n    valid_tsfm = A.Compose([\n        A.Resize(height=height, width=width),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2()\n    ])\n    \n    return {\"train\": train_tsfm, \"eval\": valid_tsfm}\n\n\ndef get_dataloaders(data, cfg, split=\"train\"):\n    img_size = cfg['img_size']\n    height, width = img_size[0], img_size[1]\n    tsfm = get_transforms(height=height, width=width)\n    if split == 'train':\n        tr_tsfm = tsfm['train']\n        ds = AerialDataset(data=data, transform=tr_tsfm)\n        labels = ds.get_labels()\n        class_weights = torch.tensor(compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels))\n        samples_weights = class_weights[labels]\n        sampler = utils.data.WeightedRandomSampler(weights=samples_weights, \n                                                   num_samples=len(samples_weights), \n                                                   replacement=True)\n#         sampler=ImbalancedDatasetSampler(ds)\n        dls = utils.data.DataLoader(ds, \n                                    batch_size=cfg['batch_size'], \n                                    sampler=sampler,\n                                    num_workers=os.cpu_count(), \n                                    drop_last=True, \n                                    pin_memory=True)\n        \n    elif split == 'valid' or split == 'test':\n        eval_tsfm = tsfm['eval']\n        ds = AerialDataset(data=data, transform=eval_tsfm)\n        dls = utils.data.DataLoader(ds, \n                                    batch_size=2*cfg['batch_size'], \n                                    shuffle=False, \n                                    num_workers=os.cpu_count(), \n                                    drop_last=False, \n                                    pin_memory=True)\n    else:\n        raise Exception(\"Split should be 'train' or 'valid' or 'test'!!!\")\n    return dls","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:32.296716Z","iopub.execute_input":"2024-05-19T03:48:32.297028Z","iopub.status.idle":"2024-05-19T03:48:32.313261Z","shell.execute_reply.started":"2024-05-19T03:48:32.296998Z","shell.execute_reply":"2024-05-19T03:48:32.312265Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def check_class_distribution(data_loader):\n    for i, batch in enumerate(data_loader):\n        labels = batch['target']\n        class_distribution = Counter(labels.numpy())\n        print(f\"Batch {i+1}: Class Distribution: {class_distribution}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:32.314324Z","iopub.execute_input":"2024-05-19T03:48:32.315465Z","iopub.status.idle":"2024-05-19T03:48:32.326221Z","shell.execute_reply.started":"2024-05-19T03:48:32.315428Z","shell.execute_reply":"2024-05-19T03:48:32.325393Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# kfold = model_selacosection.GroupKFold(n_splits=5)\nkfold = model_selection.StratifiedKFold(n_splits=4, shuffle=True, random_state=2024)\nx = df.index.values\ny = df['label'].astype(int).values\n\ndf['fold'] = -1\nfor fold, (tr_idx, val_idx) in enumerate(kfold.split(x,y)):\n    df.loc[val_idx, 'fold'] = fold","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:32.327321Z","iopub.execute_input":"2024-05-19T03:48:32.327613Z","iopub.status.idle":"2024-05-19T03:48:32.344041Z","shell.execute_reply.started":"2024-05-19T03:48:32.327581Z","shell.execute_reply":"2024-05-19T03:48:32.342968Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Cross entropy loss","metadata":{}},{"cell_type":"code","source":"# class FocalLoss(nn.Module):\n#     def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n#         super(FocalLoss, self).__init__()\n#         self.alpha = alpha\n#         self.gamma = gamma\n#         self.reduction = reduction\n\n#     def forward(self, inputs, targets):\n#         BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n#         pt = torch.exp(-BCE_loss)  # prevents nans when probability 0\n#         F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n\n#         if self.reduction == 'mean':\n#             return torch.mean(F_loss)\n#         elif self.reduction == 'sum':\n#             return torch.sum(F_loss)\n#         else:\n#             return F_loss","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:32.345252Z","iopub.execute_input":"2024-05-19T03:48:32.345548Z","iopub.status.idle":"2024-05-19T03:48:32.349724Z","shell.execute_reply.started":"2024-05-19T03:48:32.345524Z","shell.execute_reply":"2024-05-19T03:48:32.348860Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# y = df['label'].astype(int).values\n# # neg_examples, pos_examples = np.bincount(df['label'].astype(int).values)\n# # pos_weights = torch.tensor([neg_examples / pos_examples])\n# # pos_weights\n# pos_weights = torch.tensor(compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y))\n# # np.unique(df['label'].astype(int).values, return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:32.350875Z","iopub.execute_input":"2024-05-19T03:48:32.351194Z","iopub.status.idle":"2024-05-19T03:48:32.358553Z","shell.execute_reply.started":"2024-05-19T03:48:32.351164Z","shell.execute_reply":"2024-05-19T03:48:32.357632Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AerialLightningModel(pl.LightningModule):\n    def __init__(self, \n                 name: str, \n                 num_classes: int = 0, \n                 pretrained: bool = False, \n                 kernel_size: int = 3, \n                 stride: int = 2, \n                 lr: float = 3e-4, dl_size: int = 0):\n        \n        super().__init__()\n        self.save_hyperparameters()\n        self.steps_per_epoch = dl_size\n        self.encoder = timm.create_model(name, pretrained=pretrained, num_classes=0)\n        nb_fts = self.encoder.num_features\n        nb_fts = nb_fts // stride\n        self.nb_fts = nb_fts if kernel_size < 3 else nb_fts - 1\n        self.avg_pool = nn.AvgPool1d(kernel_size, stride=stride)\n        \n        self.flatten = nn.Flatten()\n        self.head = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(self.nb_fts, 768),\n            nn.ReLU(),\n#             nn.BatchNorm1d(768),\n            nn.Dropout(0.2),\n            nn.Linear(768, 256),\n            nn.ReLU(),\n#             nn.BatchNorm1d(256),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes)\n        )\n        \n        self.loss_fn = nn.BCEWithLogitsLoss()\n        self.accuracy = torchmetrics.Accuracy(task='binary')\n        self.recall = torchmetrics.Recall(task='binary')\n        self.precision = torchmetrics.Precision(task='binary')\n        self.step_outputs = []\n        \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.flatten(x)\n        x = self.avg_pool(x)\n        \n        outputs = self.head(x)\n        return outputs\n    \n    def freeze_encoder(self, flag):\n        for param in self.encoder.parameters():\n            param.requires_grad = not flag\n    \n    def shared_step(self, batch, stage):\n        imgs, labels = batch['image'], batch['target']\n        preds = self.forward(imgs)\n        loss = self.loss_fn(preds.squeeze(), labels)\n#         preds = (preds.sigmoid().squeeze() > 0.5).float()\n        preds = preds.sigmoid().squeeze()\n        acc = self.accuracy(preds, labels)\n        recall = self.recall(preds, labels)\n        precision = self.precision(preds, labels)\n        \n        self.log(f'{stage}_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log(f'{stage}_acc', acc, on_step=False, on_epoch=True, prog_bar=False)\n        self.log(f'{stage}_recall', recall, on_step=False, on_epoch=True, prog_bar=False)\n        self.log(f\"{stage}_precision\", precision, on_step=False, on_epoch=True, prog_bar=False)\n        \n        output = {\n            f\"{stage}_loss\": loss,\n            f\"{stage}_acc\": acc,\n            f\"{stage}_recall\": recall,\n            f\"{stage}_precision\": precision,\n            f\"{stage}_labels\": labels,\n            f\"{stage}_preds\": preds\n        }\n        self.step_outputs.append(output)\n        return output\n    \n    def training_step(self, batch, batch_idx):\n        output = self.shared_step(batch, 'train')\n        loss = output['train_loss']\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n#         output = self.shared_step(batch, 'val')\n#         labels, preds = output['val_labels'], output['val_preds']\n#         if batch_idx % 10 == 1:\n#             sys.stdout.write('\\033[F'*n)\n#             sys.stdout.write('\\033[K')\n#             print(f\"Batch idx: {batch_idx} -> Labels: {labels}, Preds: {preds}\")\n#             sys.stdout.flush()\n            \n#         clear_output(wait=True)\n        return self.shared_step(batch, 'val')\n            \n\n    def test_step(self, batch, batch_idx):\n        return self.shared_step(batch, 'test')\n\n    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n        return self(batch)\n    \n    def configure_optimizers(self):\n        max_epochs = self.trainer.max_epochs\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n#         scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n#         scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs, eta_min=0)\n        \n        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            optimizer, T_0=10, T_mult=2)\n        \n#         scheduler = torch.optim.lr_scheduler.OneCycleLR(\n#             optimizer=optimizer, epochs=max_epochs,\n#             pct_start=0.0, steps_per_epoch=self.steps_per_epoch,\n#             max_lr=self.hparams.lr, div_factor=25, final_div_factor=4.0e-01\n#         )\n        \n        return [optimizer], [scheduler]","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:32.359837Z","iopub.execute_input":"2024-05-19T03:48:32.360094Z","iopub.status.idle":"2024-05-19T03:48:32.381482Z","shell.execute_reply.started":"2024-05-19T03:48:32.360072Z","shell.execute_reply":"2024-05-19T03:48:32.380538Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"CONFIG['patience'] = 8 if CONFIG['epochs'] < 50 else 12\nfor fold in range(4):\n    train_data = df[df['fold'] != fold].reset_index(drop=True)\n    valid_data = df[df['fold'] == fold].reset_index(drop=True)\n    train_dls = get_dataloaders(train_data, cfg=CONFIG, split='train')\n    valid_dls = get_dataloaders(valid_data, cfg=CONFIG, split=\"valid\")\n\n    net = AerialLightningModel(name='efficientnet_b0.ra_in1k', \n                               num_classes=1, \n                               pretrained=True, \n                               lr=1e-5, dl_size=len(train_dls))\n    # net.freeze_encoder(True)\n\n    wandb_logger = WandbLogger(project=\"Plastic-Optics-classification\",\n                               checkpoint_name=f\"aerialModel_fold_{fold}\", \n                               log_model=\"all\")\n\n    callbacks = [\n        ModelCheckpoint(save_weights_only=True, \n                        mode=\"min\", \n                        monitor=\"val_loss\"),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n        LearningRateMonitor(\"epoch\"),\n        EarlyStopping(monitor=\"val_loss\", min_delta=0.0, patience=CONFIG['patience'], verbose=False, mode=\"min\"),\n    ]\n\n    trainer = pl.Trainer(max_epochs=CONFIG['epochs'], logger=wandb_logger, callbacks=callbacks)\n#     trainer = pl.Trainer(max_epochs=10)\n    trainer.fit(net, train_dataloaders=train_dls, val_dataloaders=valid_dls)\n    break\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:48:32.382708Z","iopub.execute_input":"2024-05-19T03:48:32.383038Z","iopub.status.idle":"2024-05-19T08:17:20.447326Z","shell.execute_reply.started":"2024-05-19T03:48:32.383008Z","shell.execute_reply":"2024-05-19T08:17:20.446557Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0350494272b4447a89e8d3a6545e6d81"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamu2505\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>./wandb/run-20240519_034833-mio13xyv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samu2505/Plastic-Optics-classification/runs/mio13xyv' target=\"_blank\">devout-mountain-7</a></strong> to <a href='https://wandb.ai/samu2505/Plastic-Optics-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samu2505/Plastic-Optics-classification' target=\"_blank\">https://wandb.ai/samu2505/Plastic-Optics-classification</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samu2505/Plastic-Optics-classification/runs/mio13xyv' target=\"_blank\">https://wandb.ai/samu2505/Plastic-Optics-classification/runs/mio13xyv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73138b571ba24d9a802835a278bb7f70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67fa1c797ac3425ba802943f1b929a5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0204561d63748ad88b6e5fdc6d27ec2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4401ac4e87aa4ebf87b6e88ab48a3141"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48a51f19dc954830b14ca6e4baecba0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"443af668cfde48029b58a8fd67af3b16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edb430b65e94495c84d052ae5edd235e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77cb6dfd99954e11b8379b37a789dede"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"306b93d99b2e4b1b953f2e2a9f0d5c82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0431a9aadc64c589e7de9aecb544a86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d53215475ac4288860b25457a053a80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd1cc703650b4fb19a73d111027f653c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bc0d1cee9ac43178125e919d8d4adc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f55f2e8cd14544209eb91f91d3dbd907"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"342a2f44445e42f096864ec272cec513"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"357920d0aa4449c9a15e4ff5c94a9657"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cc01c3647b546469c520898678c6f41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c865ed5575e2419fb3b01e2d038a82b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13e23add3f0d4d42b0e8ea3d5ebe8eb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0c3022ff7454bd9b3dd3e7dca7c36a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6931b40f10b84c8f878a19ea5f68cc52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f902504e690a45a3aff5b4cc4ff5d25d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5ad5058e1d04fbe95dd21abc1487f01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be0414aa59c2492489c971453baa2e9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f167f8794f5946ceaee90fcacf7c2732"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca97ea4ccf4947b0b6d1e73ead591fba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f1271d104f943578433ab8a8ad08f47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"603a2a4659a7494495d8b38dabe8215b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e19b55d7dd854065b898b93ee8edff08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30f0d7642dcd446fac6c03c358aba125"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eceb0275ff754389a836321a25cc57ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"150d7941f75c439982ada21a77fc6925"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b8eaa8a6cf34cc78e3076bdb5327ccc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01de56428e20481683589dacb3454a8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fd06c8bbe344088b507817e5542aaa5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2ddb0236b9749e6a5f767a007e1ce62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00b3022a5ac449c2974ce4c6b62fc385"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"759a77c795354d8cb123104468d7f981"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d9b2bcd5510426e97f6a8814ef2bf58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b66ca7989a374b6bbf53ab28a70ef9e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"699095f4a2624160b772950ab663b752"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caee23f351a94f45b2a02f10f7d9602e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"002a6f7ef2c840808213531ae4ffa5f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22cc2f96a7c44ecda2631e645901d33d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ad7ea59f36b46dc93fcebea50b3bc07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1d8890812474273b36c2100d331ad0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='309.451 MB of 309.451 MB uploaded\\r'), FloatProgress(value=0.9999983019149068, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66e30176cf974e62957055f11a94b4f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>██▇▇▆▄▃▂▂▁███▇▇▇▆▆▅▄▃▃▂▂▂▁▁▁██████▇▇▇▇▇▆</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█████████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▅▄▃▅▄▄▄▂▅▂▃▄▄▂▄▂▅▅▂▅▄▁▄▂▁▄▂▃▃▃▄▃▃▃▂▂▂</td></tr><tr><td>train_precision</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███████</td></tr><tr><td>train_recall</td><td>█▃▂▁▂▂▃▃▃▂▃▃▃▃▃▃▄▃▄▄▄▄▄▄▄▄▅▄▄▅▄▅▅▅▄▅▅▅▅▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▁▃▁▁▁▁▁▁▄▂▄▂▂▂▂▂▂▆▂▆▂▂▂▂▂▂█▂█▂▂▂</td></tr><tr><td>val_acc</td><td>▁▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇█▇█████████▇▇███████████</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▅▄▃▂▄▃▂▃▃▃▁▃▂▃▃▃▂▃▂▃▂▂▂▃▃▂▄▃▃▂▂▂▁▃▂▂▃▃▃</td></tr><tr><td>val_precision</td><td>▁▂▃▄▄▄▅▄▄▅▅▆▆▆▆▆▆▆▇▇▆▆▆▇▆▆▇▆▆▇▇▇▇▇▇██▇▇█</td></tr><tr><td>val_recall</td><td>█▅▄▃▄▃▃▄▄▃▄▃▄▃▂▄▄▃▁▄▂▃▃▁▃▂▂▄▃▂▂▂▂▃▄▁▁▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>43</td></tr><tr><td>lr-Adam</td><td>1e-05</td></tr><tr><td>train_acc</td><td>0.93878</td></tr><tr><td>train_loss_epoch</td><td>0.1554</td></tr><tr><td>train_loss_step</td><td>0.13625</td></tr><tr><td>train_precision</td><td>0.92638</td></tr><tr><td>train_recall</td><td>0.9561</td></tr><tr><td>trainer/global_step</td><td>8623</td></tr><tr><td>val_acc</td><td>0.9054</td></tr><tr><td>val_loss_epoch</td><td>0.25367</td></tr><tr><td>val_loss_step</td><td>0.45187</td></tr><tr><td>val_precision</td><td>0.38119</td></tr><tr><td>val_recall</td><td>0.35518</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">devout-mountain-7</strong> at: <a href='https://wandb.ai/samu2505/Plastic-Optics-classification/runs/mio13xyv' target=\"_blank\">https://wandb.ai/samu2505/Plastic-Optics-classification/runs/mio13xyv</a><br/> View project at: <a href='https://wandb.ai/samu2505/Plastic-Optics-classification' target=\"_blank\">https://wandb.ai/samu2505/Plastic-Optics-classification</a><br/>Synced 4 W&B file(s), 0 media file(s), 17 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240519_034833-mio13xyv/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"# help(torchmetrics.Precision(task='binary', num_classes=2))\n# help(torchmetrics.Recall(task='binary'))","metadata":{"execution":{"iopub.status.busy":"2024-05-19T08:17:20.448927Z","iopub.execute_input":"2024-05-19T08:17:20.449641Z","iopub.status.idle":"2024-05-19T08:17:20.453773Z","shell.execute_reply.started":"2024-05-19T08:17:20.449597Z","shell.execute_reply":"2024-05-19T08:17:20.452799Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}