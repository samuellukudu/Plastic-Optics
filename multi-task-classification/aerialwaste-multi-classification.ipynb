{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8370534,"sourceType":"datasetVersion","datasetId":4976188}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classification","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!wget https://zenodo.org/records/7991872/files/testing.json -O testing.json\n!wget https://zenodo.org/records/7991872/files/training.json -O training.json","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:31:45.679714Z","iopub.execute_input":"2024-05-26T03:31:45.680519Z","iopub.status.idle":"2024-05-26T03:31:50.217184Z","shell.execute_reply.started":"2024-05-26T03:31:45.680485Z","shell.execute_reply":"2024-05-26T03:31:50.215953Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2024-05-26 03:31:46--  https://zenodo.org/records/7991872/files/testing.json\nResolving zenodo.org (zenodo.org)... 188.184.103.159, 188.185.79.172, 188.184.98.238, ...\nConnecting to zenodo.org (zenodo.org)|188.184.103.159|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1696233 (1.6M) [text/plain]\nSaving to: 'testing.json'\n\ntesting.json        100%[===================>]   1.62M  2.40MB/s    in 0.7s    \n\n2024-05-26 03:31:47 (2.40 MB/s) - 'testing.json' saved [1696233/1696233]\n\n--2024-05-26 03:31:48--  https://zenodo.org/records/7991872/files/training.json\nResolving zenodo.org (zenodo.org)... 188.184.98.238, 188.184.103.159, 188.185.79.172, ...\nConnecting to zenodo.org (zenodo.org)|188.184.98.238|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3142168 (3.0M) [text/plain]\nSaving to: 'training.json'\n\ntraining.json       100%[===================>]   3.00M  3.79MB/s    in 0.8s    \n\n2024-05-26 03:31:50 (3.79 MB/s) - 'training.json' saved [3142168/3142168]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q torchsampler\n!pip install -q torchmetrics\n!pip install -qU wandb","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:31:50.219209Z","iopub.execute_input":"2024-05-26T03:31:50.219544Z","iopub.status.idle":"2024-05-26T03:32:32.251024Z","shell.execute_reply.started":"2024-05-26T03:31:50.219511Z","shell.execute_reply":"2024-05-26T03:32:32.249801Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os, gc, sys, yaml, json, copy\nfrom pathlib import Path\nimport glob\nfrom collections import Counter, defaultdict\nfrom tqdm.auto import tqdm\ntqdm.pandas()\n\nimport math\nimport random\nimport numpy as np\nimport pandas as pd\n\nimport cv2\nimport PIL\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import model_selection\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import utils\nfrom torchvision import transforms as T\n\nimport timm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torchsampler import ImbalancedDatasetSampler\nimport torchmetrics\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:32:32.252420Z","iopub.execute_input":"2024-05-26T03:32:32.252693Z","iopub.status.idle":"2024-05-26T03:32:43.208749Z","shell.execute_reply.started":"2024-05-26T03:32:32.252667Z","shell.execute_reply":"2024-05-26T03:32:43.207592Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"WANDB_API_KEY\")\nwandb.login(key=secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:32:43.210869Z","iopub.execute_input":"2024-05-26T03:32:43.211406Z","iopub.status.idle":"2024-05-26T03:32:45.129118Z","shell.execute_reply.started":"2024-05-26T03:32:43.211375Z","shell.execute_reply":"2024-05-26T03:32:45.128165Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"CONFIG = dict(\n    img_size = [512, 512],\n    batch_size = 16,\n    epochs = 50,\n    seed = 42,\n    device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n)\n\ndef seeding(SEED):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    torch.manual_seed(SEED)\n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(SEED)\n        torch.cuda.manual_seed_all(SEED)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n#     os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n#     tf.random.set_seed(SEED)\n#     keras.utils.set_random_seed(seed=SEED)\n    print('seeding done!!!')\n\ndef flush():\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.reset_peak_memory_stats()\n        \nseeding(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:32:45.130329Z","iopub.execute_input":"2024-05-26T03:32:45.130824Z","iopub.status.idle":"2024-05-26T03:32:45.161823Z","shell.execute_reply.started":"2024-05-26T03:32:45.130797Z","shell.execute_reply":"2024-05-26T03:32:45.160876Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"seeding done!!!\n","output_type":"stream"}]},{"cell_type":"code","source":"DATA_DIR = Path(\"/kaggle/input/aerial-dataset\")\nIMAGE_PATHS = glob.glob(\"/kaggle/input/aerial-dataset/*/*.png\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:32:45.162893Z","iopub.execute_input":"2024-05-26T03:32:45.163194Z","iopub.status.idle":"2024-05-26T03:32:47.826435Z","shell.execute_reply.started":"2024-05-26T03:32:45.163169Z","shell.execute_reply":"2024-05-26T03:32:47.825402Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"image_df = pd.DataFrame(IMAGE_PATHS, columns=['image_path'])\n\ncheck_path = lambda path: os.path.exists(path)\nget_image_dir = lambda path: int(Path(path).stem)\nimage_df['image_id'] = image_df['image_path'].map(get_image_dir)\nimage_df['exists'] = image_df['image_path'].map(check_path)\nimage_df['exists'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:32:47.827535Z","iopub.execute_input":"2024-05-26T03:32:47.827826Z","iopub.status.idle":"2024-05-26T03:33:00.948138Z","shell.execute_reply.started":"2024-05-26T03:32:47.827800Z","shell.execute_reply":"2024-05-26T03:33:00.947233Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"exists\nTrue    10977\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"with open(\"/kaggle/working/training.json\", \"r\") as f:\n    data = json.loads(f.read())","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:00.949392Z","iopub.execute_input":"2024-05-26T03:33:00.949679Z","iopub.status.idle":"2024-05-26T03:33:01.228496Z","shell.execute_reply.started":"2024-05-26T03:33:00.949655Z","shell.execute_reply":"2024-05-26T03:33:01.227516Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = pd.json_normalize(data, record_path=['images'])\ndf.rename(columns={'id': 'image_id'}, inplace=True)\ndf = df.merge(image_df, how='left', on='image_id')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:01.229753Z","iopub.execute_input":"2024-05-26T03:33:01.230053Z","iopub.status.idle":"2024-05-26T03:33:01.560113Z","shell.execute_reply.started":"2024-05-26T03:33:01.230028Z","shell.execute_reply":"2024-05-26T03:33:01.559148Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"  file_name  image_id  categories img_source  width  height      site_type  \\\n0  3456.png      3456         [1]       AGEA   1055    1046            n/s   \n1  2423.png      2423  [1, 2, 16]        WV3    697     698  Degraded area   \n2  3245.png      3245          []       AGEA   1036    1065            n/s   \n3  3330.png      3330          []       AGEA   1038    1063            n/s   \n4  2957.png      2957          []       AGEA   1044    1058            n/s   \n\n  severity evidence  is_candidate_location  valid_fine_grain  \\\n0      n/s      n/s                      1                 1   \n1        1        2                      1                 1   \n2      n/s        3                      1                 0   \n3      n/s        1                      1                 0   \n4      n/s        2                      1                 0   \n\n                                      image_path  exists  \n0  /kaggle/input/aerial-dataset/images2/3456.png    True  \n1  /kaggle/input/aerial-dataset/images0/2423.png    True  \n2  /kaggle/input/aerial-dataset/images1/3245.png    True  \n3  /kaggle/input/aerial-dataset/images1/3330.png    True  \n4  /kaggle/input/aerial-dataset/images3/2957.png    True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>image_id</th>\n      <th>categories</th>\n      <th>img_source</th>\n      <th>width</th>\n      <th>height</th>\n      <th>site_type</th>\n      <th>severity</th>\n      <th>evidence</th>\n      <th>is_candidate_location</th>\n      <th>valid_fine_grain</th>\n      <th>image_path</th>\n      <th>exists</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3456.png</td>\n      <td>3456</td>\n      <td>[1]</td>\n      <td>AGEA</td>\n      <td>1055</td>\n      <td>1046</td>\n      <td>n/s</td>\n      <td>n/s</td>\n      <td>n/s</td>\n      <td>1</td>\n      <td>1</td>\n      <td>/kaggle/input/aerial-dataset/images2/3456.png</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2423.png</td>\n      <td>2423</td>\n      <td>[1, 2, 16]</td>\n      <td>WV3</td>\n      <td>697</td>\n      <td>698</td>\n      <td>Degraded area</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>/kaggle/input/aerial-dataset/images0/2423.png</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3245.png</td>\n      <td>3245</td>\n      <td>[]</td>\n      <td>AGEA</td>\n      <td>1036</td>\n      <td>1065</td>\n      <td>n/s</td>\n      <td>n/s</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>/kaggle/input/aerial-dataset/images1/3245.png</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3330.png</td>\n      <td>3330</td>\n      <td>[]</td>\n      <td>AGEA</td>\n      <td>1038</td>\n      <td>1063</td>\n      <td>n/s</td>\n      <td>n/s</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>/kaggle/input/aerial-dataset/images1/3330.png</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2957.png</td>\n      <td>2957</td>\n      <td>[]</td>\n      <td>AGEA</td>\n      <td>1044</td>\n      <td>1058</td>\n      <td>n/s</td>\n      <td>n/s</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>/kaggle/input/aerial-dataset/images3/2957.png</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# train_filtered['site_type'].value_counts().plot(kind='bar', rot=45);\nplt.figure(figsize=(10, 5))\nax = sns.countplot(x='is_candidate_location', data=df)\n# ax.set_xticklabels(ax.get_xticklabels(), rotation=60, ha='right')\nplt.tight_layout()\nplt.title(\"Distribution of landfill candidate location in Data\")\nplt.savefig(\"landfill_distribution.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:01.564157Z","iopub.execute_input":"2024-05-26T03:33:01.564533Z","iopub.status.idle":"2024-05-26T03:33:01.996814Z","shell.execute_reply.started":"2024-05-26T03:33:01.564507Z","shell.execute_reply":"2024-05-26T03:33:01.995937Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# # Assuming 'df' is your DataFrame and 'is_candidate_location' is the column of interest\n# data = df['is_candidate_location'].value_counts()\n\n# # Calculate percentages\n# percentages = data / data.sum() * 100\n\n# # Define the separation of sectors\n# explode = [0.1] * len(data)  # This will separate all sectors slightly. Adjust as needed.\n\n# # Create the pie chart\n# plt.figure(figsize=(10, 5))\n# plt.pie(data, labels=data.index, autopct='%1.1f%%', startangle=140, explode=explode)\n\n# # Draw a circle at the center to turn the pie into a donut\n# # centre_circle = plt.Circle((0,0),0.70,fc='white')\n# # fig = plt.gcf()\n# # fig.gca().add_artist(centre_circle)\n\n# # Equal aspect ratio ensures that pie is drawn as a circle.\n# plt.axis('equal')  \n# plt.title(\"Distribution of Landfill Candidate Location in Data\")\n\n# # Save the figure\n# plt.savefig(\"landfill_distribution_pie.png\")\n\n# # Show the plot\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:01.997960Z","iopub.execute_input":"2024-05-26T03:33:01.998238Z","iopub.status.idle":"2024-05-26T03:33:02.002865Z","shell.execute_reply.started":"2024-05-26T03:33:01.998214Z","shell.execute_reply":"2024-05-26T03:33:02.002029Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Preview\n\n**If landfill location is detected**\n\n- **Check for severity perceived by the analyst at annotation (from 0 to 3)**\n    \n- **Check for evidence perceived by the analyst at annotation (from 0 to 3)**\n\n- **Type of site (e.g production area)**\n\n**If valid fine grain**\n\nImage analyzed to observe Waste objects or storage modes present\n\n- **Find the categories of waste objects or storage modes present on the images**","metadata":{}},{"cell_type":"code","source":"train_df = df[~df['evidence'].isin(['n/a', 'n/s']) & ~df['severity'].isin(['n/a', 'n/s'])].reset_index(drop=True)\ntest_df = df[df['evidence'].isin(['n/a', 'n/s']) & df['severity'].isin(['n/a', 'n/s'])].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.004050Z","iopub.execute_input":"2024-05-26T03:33:02.004414Z","iopub.status.idle":"2024-05-26T03:33:02.027500Z","shell.execute_reply.started":"2024-05-26T03:33:02.004390Z","shell.execute_reply":"2024-05-26T03:33:02.026466Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# # Set the aesthetic style of the plots\n# sns.set_style('whitegrid')\n\n# # Plot the distribution of 'evidence' in the training data\n# # plt.figure(figsize=(10, 6))\n# # sns.countplot(x='evidence', data=train_df)\n# # plt.title('Distribution of Evidence in Training Data')\n# # plt.show()\n\n# # Plot the distribution of 'severity' in the training data\n# plt.figure(figsize=(10, 6))\n# sns.countplot(x='severity', data=train_df)\n# plt.title('Distribution of Severity in Data')\n# plt.savefig('severity.png')\n# plt.show()\n\n# # # Plot the distribution of 'evidence' in the testing data\n# # plt.figure(figsize=(10, 6))\n# # sns.countplot(x='evidence', data=test_df)\n# # plt.title('Distribution of Evidence in Testing Data')\n# # plt.show()\n\n# # # Plot the distribution of 'severity' in the testing data\n# # plt.figure(figsize=(10, 6))\n# # sns.countplot(x='severity', data=test_df)\n# # plt.title('Distribution of Severity in Testing Data')\n# # plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.028751Z","iopub.execute_input":"2024-05-26T03:33:02.029041Z","iopub.status.idle":"2024-05-26T03:33:02.034026Z","shell.execute_reply.started":"2024-05-26T03:33:02.029016Z","shell.execute_reply":"2024-05-26T03:33:02.032991Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# # Bar plot for the 'severity' variable in the training data\n# plt.figure(figsize=(15, 5))\n# sns.barplot(x='site_type', y='severity', data=train_filtered, errorbar=None)\n# plt.title('Severity by Site Type in Training Data Where is_candidate_location is True')\n# plt.show()\n\n# plt.figure(figsize=(15, 5))\n# sns.barplot(x='site_type', y='evidence', data=train_filtered, errorbar=None)\n# plt.title('Evidence by Site Type in Training Data Where is_candidate_location is True')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.035404Z","iopub.execute_input":"2024-05-26T03:33:02.036101Z","iopub.status.idle":"2024-05-26T03:33:02.046894Z","shell.execute_reply.started":"2024-05-26T03:33:02.036049Z","shell.execute_reply":"2024-05-26T03:33:02.045953Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# # Filter the dataframes where 'is_candidate_location' is True\n# train_filtered = train_df[train_df['is_candidate_location']==1]\n# test_filtered = test_df[test_df['is_candidate_location']==1]\n\n# # Set the aesthetic style of the plots\n# sns.set_style('whitegrid')\n\n# # Visualize the distribution of 'site_type' with respect to 'severity' in the training data\n# plt.figure(figsize=(15, 5))\n# sns.countplot(x='site_type', hue='severity', data=train_filtered, palette='viridis')\n# plt.title('Distribution of Site Type by Severity in Data')\n# plt.legend(title='Severity')\n# plt.savefig('site_severity.png')\n# plt.show()\n\n# # plt.figure(figsize=(15, 5))\n# # sns.countplot(x='site_type', hue='evidence', data=train_filtered, palette='viridis')\n# # plt.title('Distribution of Site Type by Severity in Data')\n# # plt.legend(title='Evidence')\n# # plt.show()\n\n# # Visualize the distribution of 'site_type' with respect to 'evidence' in the training data\n# # plt.figure(figsize=(10, 6))\n# # # Rotate the x-labels to prevent overlap\n# # g.set_xticklabels(rotation=45)\n# # # Adjust the spacing between the facets\n# # g.fig.subplots_adjust(wspace=0.2)\n# # # Set the super title for the entire plot\n# # g.fig.suptitle('Site Type by Evidence and Severity in Training Data', y=1.05)\n# # plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.048051Z","iopub.execute_input":"2024-05-26T03:33:02.048449Z","iopub.status.idle":"2024-05-26T03:33:02.056978Z","shell.execute_reply.started":"2024-05-26T03:33:02.048424Z","shell.execute_reply":"2024-05-26T03:33:02.056265Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# # train_filtered['site_type'].value_counts().plot(kind='bar', rot=45);\n# plt.figure(figsize=(10, 5))\n# ax = sns.countplot(x='site_type', data=train_filtered)\n# ax.set_xticklabels(ax.get_xticklabels(), rotation=60, ha='right')\n# plt.tight_layout()\n# plt.title(\"Distribution of site types in Data\")\n# plt.savefig(\"site_distribution.png\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.058810Z","iopub.execute_input":"2024-05-26T03:33:02.059181Z","iopub.status.idle":"2024-05-26T03:33:02.069139Z","shell.execute_reply.started":"2024-05-26T03:33:02.059152Z","shell.execute_reply":"2024-05-26T03:33:02.068397Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# # Create a catplot and set the size of each facet\n# g = sns.catplot(x='site_type', \n#                 hue='evidence', \n#                 col='severity', \n#                 data=train_filtered, \n#                 kind='count', \n#                 palette='viridis', \n#                 height=6, \n#                 aspect=1)\n\n# # Rotate the x-labels to prevent overlap\n# g.set_xticklabels(rotation=45)\n\n# # Adjust the spacing between the facets\n# g.fig.subplots_adjust(wspace=0.2)\n\n# # Set the super title for the entire plot\n# g.fig.suptitle('Site Type by Evidence and Severity in Training Data', y=1.05)\n\n# # Show the plot\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.070279Z","iopub.execute_input":"2024-05-26T03:33:02.070534Z","iopub.status.idle":"2024-05-26T03:33:02.078200Z","shell.execute_reply.started":"2024-05-26T03:33:02.070513Z","shell.execute_reply":"2024-05-26T03:33:02.077267Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# import seaborn as sns\n# import matplotlib.pyplot as plt\n# import pandas as pd\n\n# # Assuming 'train_filtered' is your filtered training DataFrame\n# # Create a contingency table\n# contingency_table = pd.crosstab(train_filtered['severity'], train_filtered['evidence'])\n\n# # Create a heatmap\n# plt.figure(figsize=(10, 8))\n# sns.heatmap(contingency_table, \n#             cmap='coolwarm', \n#             annot=True, \n#             fmt='d', \n#             linewidths=0.5, \n#             linecolor='grey', \n#             cbar=True, \n#             square=True,\n#             vmin=0, \n#             vmax=100)\n# plt.xticks(rotation=45)\n# plt.yticks(rotation=0)\n# plt.title('Customized Heatmap of Severity vs Evidence')\n# plt.xlabel('Evidence')\n# plt.ylabel('Severity')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.079333Z","iopub.execute_input":"2024-05-26T03:33:02.079590Z","iopub.status.idle":"2024-05-26T03:33:02.091128Z","shell.execute_reply.started":"2024-05-26T03:33:02.079568Z","shell.execute_reply":"2024-05-26T03:33:02.090252Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# test_df['is_candidate_location'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.092210Z","iopub.execute_input":"2024-05-26T03:33:02.092496Z","iopub.status.idle":"2024-05-26T03:33:02.100605Z","shell.execute_reply.started":"2024-05-26T03:33:02.092473Z","shell.execute_reply":"2024-05-26T03:33:02.099614Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"sites = train_df['site_type'].unique().tolist()\nid2label = {k:v for k,v in enumerate(sites)}\nlabel2id = {v:k for k,v in id2label.items()}\n\ntrain_df['target_site'] = train_df['site_type'].map(label2id)\ntrain_df['target_site'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.101722Z","iopub.execute_input":"2024-05-26T03:33:02.101953Z","iopub.status.idle":"2024-05-26T03:33:02.115267Z","shell.execute_reply.started":"2024-05-26T03:33:02.101933Z","shell.execute_reply":"2024-05-26T03:33:02.114459Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"target_site\n1    836\n2    478\n0    395\n5    165\n4     94\n3     88\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"class AerialMultiDataset(utils.data.Dataset):\n    \n    def __init__(self, data, transform, mode='train', label_name='severity'):\n        super().__init__()\n        self.data = data\n        self.tsfm = transform\n        self.mode = mode\n        self.label = data.loc[:, label_name]\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img_path = self.data.loc[idx, 'image_path']\n        severity = self.data.loc[idx, 'severity']\n#         evidence = self.data.loc[idx, 'evidence']\n        site = self.data.loc[idx, 'target_site']\n        \n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = self.tsfm(image=image)['image']\n        \n        return {\"image\": image, \n                \"severity\": torch.tensor(severity, dtype=torch.long), \n#                 \"evidence\": torch.tensor(evidence, dtype=torch.long),\n                \"site\": torch.tensor(site, dtype=torch.long)\n               }\n    \n    def get_labels(self):\n        return self.label\n    \nclass MultiLabelDataset(utils.data.Dataset):\n    \n    def __init__(self, data, transform, mode='train', label_name='severity'):\n        super().__init__()\n        self.data = data\n        self.tsfm = transform\n        self.mode = mode\n        self.label = data.loc[:, label_name]\n        self.num_site_classes = 6\n        self.num_severe_classes = 4\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img_path = self.data.loc[idx, 'image_path']\n        severity = self.data.loc[idx, 'severity']\n        site = self.data.loc[idx, 'target_site']\n        \n        severe_vector = torch.zeros(self.num_severe_classes)\n        severe_vector[severity] = 1\n        site_vector = torch.zeros(self.num_site_classes)\n        site_vector[site] = 1\n        \n        \n        \n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = self.tsfm(image=image)['image']\n        \n        return {\"image\": image, \n                \"severity\": severe_vector, \n                \"site\": site_vector,\n               }\n    \n    def get_labels(self):\n        return self.label","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.116380Z","iopub.execute_input":"2024-05-26T03:33:02.116642Z","iopub.status.idle":"2024-05-26T03:33:02.130452Z","shell.execute_reply.started":"2024-05-26T03:33:02.116619Z","shell.execute_reply":"2024-05-26T03:33:02.129624Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# def get_transforms(height, width):\n#     train_tsfm = A.Compose([\n#         A.Resize(height=height, width=width),\n#         A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.5),\n#         A.RGBShift(r_shift_limit=25, g_shift_limit=25, b_shift_limit=25, p=0.5),\n        \n#         A.OneOf([\n#             A.RandomRain(brightness_coefficient=0.9, drop_width=1, blur_value=5, p=1),\n#             A.RandomSnow(brightness_coeff=2.5, snow_point_lower=0.3, snow_point_upper=0.5, p=1),\n#             A.RandomFog(fog_coef_lower=0.7, fog_coef_upper=0.8, alpha_coef=0.1, p=1),\n#         ], p=0.3),\n        \n#         A.OneOf([\n#             A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), angle_lower=0.5, p=1),\n#             A.RandomShadow(num_shadows_lower=1, num_shadows_upper=1, shadow_dimension=5, shadow_roi=(0, 0.5, 1, 1), p=1),\n#         ], p=0.2),\n        \n#         A.Normalize(mean=[0.485, 0.456, 0.406],\n#                    std=[0.229, 0.224, 0.225]),\n#         ToTensorV2()\n#     ])\n    \n#     valid_tsfm = A.Compose([\n#         A.Resize(height=height, width=width),\n#         A.Normalize(mean=[0.485, 0.456, 0.406],\n#                    std=[0.229, 0.224, 0.225]),\n#         ToTensorV2()\n#     ])\n#     return {\"train\": train_tsfm, \"eval\": valid_tsfm}\n\ndef get_transforms(height, width):\n    train_tsfm = A.Compose([\n        # Geometric augmentations\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.RandomRotate90(p=0.5),\n#         A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.5),\n        # Photometric augmentations\n#         A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n#         A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n#         A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n        \n        A.Resize(height=height, width=width),\n        # Normalization and conversion to tensor\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2()\n    ])\n    \n    valid_tsfm = A.Compose([\n        A.Resize(height=height, width=width),\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2()\n    ])\n    \n    return {\"train\": train_tsfm, \"eval\": valid_tsfm}\n\ndef get_dataloaders(data, cfg, split=\"train\", multi=False):\n    img_size = cfg['img_size']\n    height, width = img_size[0], img_size[1]\n    tsfm = get_transforms(height=height, width=width)\n    if split == 'train':\n        tr_tsfm = tsfm['train']\n        if multi:\n            ds = MultiLabelDataset(data=data, transform=tr_tsfm)\n        else:\n            ds = AerialMultiDataset(data=data, transform=tr_tsfm)\n            \n        labels = ds.get_labels()\n        class_weights = torch.tensor(compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels))\n        samples_weights = class_weights[labels]\n\n        sampler = utils.data.WeightedRandomSampler(weights=samples_weights, \n                                                   num_samples=len(samples_weights), \n                                                   replacement=True)\n\n#         sampler=ImbalancedDatasetSampler(ds)\n        dls = utils.data.DataLoader(ds, \n                                    batch_size=cfg['batch_size'], \n                                    sampler=sampler,\n                                    num_workers=os.cpu_count(), \n                                    drop_last=True, \n                                    pin_memory=True)\n        \n    elif split == 'valid' or split == 'test':\n        eval_tsfm = tsfm['eval']\n        if multi:\n            ds = MultiLabelDataset(data=data, transform=eval_tsfm)\n        else:\n            ds = AerialMultiDataset(data=data, transform=eval_tsfm)\n        dls = utils.data.DataLoader(ds, \n                                    batch_size=2*cfg['batch_size'], \n                                    shuffle=False, \n                                    num_workers=os.cpu_count(), \n                                    drop_last=False, \n                                    pin_memory=True)\n    else:\n        raise Exception(\"Split should be 'train' or 'valid' or 'test'!!!\")\n    return dls","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.131767Z","iopub.execute_input":"2024-05-26T03:33:02.132120Z","iopub.status.idle":"2024-05-26T03:33:02.148601Z","shell.execute_reply.started":"2024-05-26T03:33:02.132056Z","shell.execute_reply":"2024-05-26T03:33:02.147806Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# # A.Normalize(mean=[0.485, 0.456, 0.406],\n# #                         std=[0.229, 0.224, 0.225]),\n\n# ts = A.Compose([\n#     A.Resize(height=512, width=512),\n#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n#     ToTensorV2()\n# ])\n\n# ds = MultiLabelDataset(data=train_df, transform=ts)\n# dls = utils.data.DataLoader(ds, batch_size=8, shuffle=True, num_workers=os.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.149736Z","iopub.execute_input":"2024-05-26T03:33:02.150087Z","iopub.status.idle":"2024-05-26T03:33:02.161252Z","shell.execute_reply.started":"2024-05-26T03:33:02.150046Z","shell.execute_reply":"2024-05-26T03:33:02.160386Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# batch = next(iter(dls))\n# torch.argmax(batch['site'], dim=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.162349Z","iopub.execute_input":"2024-05-26T03:33:02.162693Z","iopub.status.idle":"2024-05-26T03:33:02.170665Z","shell.execute_reply.started":"2024-05-26T03:33:02.162663Z","shell.execute_reply":"2024-05-26T03:33:02.169858Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def check_class_distribution(data_loader):\n    for i, batch in enumerate(data_loader):\n        labels = batch['severity']\n        class_distribution = Counter(labels.numpy())\n        print(f\"Batch {i+1}: Class Distribution: {class_distribution}\")\n\n# Assuming `train_loader` is your DataLoader\n# check_class_distribution(dls)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.171689Z","iopub.execute_input":"2024-05-26T03:33:02.171934Z","iopub.status.idle":"2024-05-26T03:33:02.180581Z","shell.execute_reply.started":"2024-05-26T03:33:02.171913Z","shell.execute_reply":"2024-05-26T03:33:02.179762Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class AsymmetricLossOptimized(nn.Module):\n    ''' Notice - optimized version, minimizes memory allocation and gpu uploading,\n    favors inplace operations'''\n\n    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=False):\n        super(AsymmetricLossOptimized, self).__init__()\n\n        self.gamma_neg = gamma_neg\n        self.gamma_pos = gamma_pos\n        self.clip = clip\n        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n        self.eps = eps\n\n        # prevent memory allocation and gpu uploading every iteration, and encourages inplace operations\n        self.targets = self.anti_targets = self.xs_pos = self.xs_neg = self.asymmetric_w = self.loss = None\n\n    def forward(self, x, y):\n        \"\"\"\"\n        Parameters\n        ----------\n        x: input logits\n        y: targets (multi-label binarized vector)\n        \"\"\"\n\n        self.targets = y\n        self.anti_targets = 1 - y\n\n        # Calculating Probabilities\n        self.xs_pos = torch.sigmoid(x)\n        self.xs_neg = 1.0 - self.xs_pos\n\n        # Asymmetric Clipping\n        if self.clip is not None and self.clip > 0:\n            self.xs_neg.add_(self.clip).clamp_(max=1)\n\n        # Basic CE calculation\n        self.loss = self.targets * torch.log(self.xs_pos.clamp(min=self.eps))\n        self.loss.add_(self.anti_targets * torch.log(self.xs_neg.clamp(min=self.eps)))\n\n        # Asymmetric Focusing\n        if self.gamma_neg > 0 or self.gamma_pos > 0:\n            if self.disable_torch_grad_focal_loss:\n                torch.set_grad_enabled(False)\n            self.xs_pos = self.xs_pos * self.targets\n            self.xs_neg = self.xs_neg * self.anti_targets\n            self.asymmetric_w = torch.pow(1 - self.xs_pos - self.xs_neg,\n                                          self.gamma_pos * self.targets + self.gamma_neg * self.anti_targets)\n            if self.disable_torch_grad_focal_loss:\n                torch.set_grad_enabled(True)\n            self.loss *= self.asymmetric_w\n\n        return -self.loss.sum()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.181835Z","iopub.execute_input":"2024-05-26T03:33:02.182125Z","iopub.status.idle":"2024-05-26T03:33:02.195047Z","shell.execute_reply.started":"2024-05-26T03:33:02.182093Z","shell.execute_reply":"2024-05-26T03:33:02.194204Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Feature Pyramid Network","metadata":{}},{"cell_type":"code","source":"def gap2d(x, keepdims=False):\n    out = torch.mean(x.view(x.size(0), x.size(1), -1), -1)\n    if keepdims:\n        out = out.view(out.size(0), out.size(1), 1, 1)\n\n    return out\n\n\nclass MultiResnetFPN(nn.Module):\n    def __init__(self, name, site_classes, severe_classes, pretrained=False):\n        super(MultiResnetFPN, self).__init__()\n        self.site_classes = site_classes\n        self.severe_classes = severe_classes\n        self.encoder = timm.create_model(name, pretrained=pretrained, features_only=True)\n        \n        # first backbone layers\n        self.stage0 = nn.Sequential(self.encoder.conv1,\n                                   self.encoder.bn1,\n                                   self.encoder.act1,\n                                   self.encoder.maxpool)\n        \n        # Backbone layers (bottom-up layer)\n        self.stage1 = nn.Sequential(self.encoder.layer1)\n        self.stage2 = nn.Sequential(self.encoder.layer2)\n        self.stage3 = nn.Sequential(self.encoder.layer3)\n        self.stage4 = nn.Sequential(self.encoder.layer4)\n        \n        if 'resnet18' in name.lower() or 'resnet34' in name.lower():\n            in_chans = self.encoder.layer4[-1].conv2.out_channels\n        if 'resnet50' in name.lower():\n            in_chans = self.encoder.layer4[-1].conv3.out_channels\n        \n        out_chans = in_chans // 8\n        # Top Layer\n        self.toplayer = nn.Conv2d(\n            in_chans, out_chans, kernel_size=1, stride=1, padding=0)\n\n        # Lateral Layers\n        self.latlayer1 = nn.Conv2d(\n            in_chans // 2, out_chans, kernel_size=1, stride=1, padding=0)\n        self.latlayer2 = nn.Conv2d(\n            in_chans // 4, out_chans, kernel_size=1, stride=1, padding=0)\n        self.latlayer3 = nn.Conv2d(\n            out_chans, out_chans, kernel_size=1, stride=1, padding=0)\n        \n        # smooth layers\n        mid_chans = in_chans // 2 - out_chans\n        self.smooth1 = nn.Conv2d(in_chans // 4, out_chans, kernel_size=3, stride=1, padding=1)\n        self.smooth2 = nn.Conv2d(mid_chans, out_chans, kernel_size=3, stride=1, padding=1)\n        self.smooth3 = nn.Conv2d(in_chans // 2, out_chans, kernel_size=3, stride=1, padding=1)\n        \n        # fully connected layer\n        self.site_fc = nn.Linear(out_chans, site_classes)\n        self.site_classifier = nn.Linear(4*site_classes, site_classes)\n        \n        self.severe_fc = nn.Linear(out_chans, severe_classes)\n        self.severe_classifier = nn.Linear(4*severe_classes, severe_classes)\n        \n    def forward(self, x):\n        # bottom-up pathway \n        c1 = self.stage0(x)\n        c2 = self.stage1(c1)\n        c3 = self.stage2(c2).detach()\n        c4 = self.stage3(c3)\n        c5 = self.stage4(c4)\n        \n        # top-down pathway\n        p5 = self.toplayer(c5)\n        p4 = self._upsample_cat(p5, self.latlayer1(c4))\n        p3 = self._upsample_cat(p4, self.latlayer2(c3))\n        p2 = self._upsample_cat(p3, self.latlayer3(c2))\n        \n        # smoothing (de-aliasing effect)\n        p4 = self.smooth1(p4)\n        p3 = self.smooth2(p3)\n        p2 = self.smooth3(p2)\n        \n        # Global Average Pooling\n        p5 = gap2d(p5, keepdims=True)\n        p4 = gap2d(p4, keepdims=True)\n        p3 = gap2d(p3, keepdims=True)\n        p2 = gap2d(p2, keepdims=True)\n        \n        # Flattening\n        p5 = p5.view(p5.size(0), -1)\n        p4 = p4.view(p4.size(0), -1)\n        p3 = p3.view(p3.size(0), -1)\n        p2 = p2.view(p2.size(0), -1)\n        \n        # Fully connected layers\n        site_out5 = F.relu(self.site_fc(p5))\n        site_out4 = F.relu(self.site_fc(p4))\n        site_out3 = F.relu(self.site_fc(p3))\n        site_out2 = F.relu(self.site_fc(p2))\n        \n        severe_out5 = F.relu(self.severe_fc(p5))\n        severe_out4 = F.relu(self.severe_fc(p4))\n        severe_out3 = F.relu(self.severe_fc(p3))\n        severe_out2 = F.relu(self.severe_fc(p2))\n        \n        # concatenate the predictions (classification results) of each of the pyramid features\n        site_out = torch.cat([site_out5, site_out4, site_out3, site_out2], dim=1)\n        site_out = self.site_classifier(site_out)\n        \n        severe_out = torch.cat([severe_out5, severe_out4, severe_out3, severe_out2], dim=1)\n        severe_out = self.severe_classifier(severe_out)\n        return site_out, severe_out\n    \n    def _upsample_cat(self, x, y):\n        _, _, H, W = y.size()\n        upsampled_x = F.interpolate(\n            x, size=(H,W), mode=\"nearest\"\n        )\n        return torch.cat([upsampled_x, y], dim=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.196391Z","iopub.execute_input":"2024-05-26T03:33:02.196749Z","iopub.status.idle":"2024-05-26T03:33:02.221314Z","shell.execute_reply.started":"2024-05-26T03:33:02.196716Z","shell.execute_reply":"2024-05-26T03:33:02.220326Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class MetricMonitor:\n    def __init__(self, float_precision=3):\n        self.float_precision = float_precision\n        self.reset()\n\n    def reset(self):\n        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n\n    def update(self, metric_name, val):\n        metric = self.metrics[metric_name]\n\n        metric[\"val\"] += val\n        metric[\"count\"] += 1\n        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n\n    def __str__(self):\n        return \" | \".join(\n            [\n                \"{metric_name}: {avg:.{float_precision}f}\".format(\n                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n                )\n                for (metric_name, metric) in self.metrics.items()\n            ]\n        )","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.226657Z","iopub.execute_input":"2024-05-26T03:33:02.226918Z","iopub.status.idle":"2024-05-26T03:33:02.234764Z","shell.execute_reply.started":"2024-05-26T03:33:02.226896Z","shell.execute_reply":"2024-05-26T03:33:02.233965Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def shared_step(batch, criterion, params):\n    image, severe, site = batch[\"image\"], batch[\"severity\"], batch[\"site\"]\n    image = image.to(params[\"device\"], non_blocking=True)\n    severe = severe.to(params[\"device\"], non_blocking=True)\n    site = site.to(params[\"device\"], non_blocking=True)\n    site_logits, severe_logits = model.forward(image.to(torch.float32))\n    site_loss = criterion(site_logits, site.to(torch.int64))\n    prob_site = F.softmax(site_logits, dim=-1)\n    pred_site = torch.argmax(prob_site, dim=-1)\n\n    severe_loss = criterion(severe_logits, severe.to(torch.int64))\n    prob_severe = F.softmax(severe_logits, dim=-1)\n    pred_severe = torch.argmax(prob_severe, dim=-1)\n    return {\n        \"site_loss\": site_loss,\n        \"severe_loss\": severe_loss,\n        \"site_preds\": pred_site,\n        \"severe_preds\": pred_severe\n    }\n    \n    \ndef train(train_loader, model, criterion, optimizer, epoch, scaler, params):\n    metric_monitor = MetricMonitor()\n    model.train()\n    stream = tqdm(train_loader)\n    train_loss = 0\n    for i, batch in enumerate(stream, start=1):\n        optimizer.zero_grad(set_to_none=True)\n        \n        with torch.autocast(device_type='cuda', dtype=torch.float16):\n            outputs = shared_step(batch, criterion, params)\n            loss =  outputs['site_loss'] + outputs['severe_loss']\n        \n#         accuracy = METRICS['accuracy'](predictions, target)\n#         jaccard = METRICS['jaccard_index'](predictions, target)\n#         fbeta = METRICS['fbeta_score'](predictions, target)\n        \n        metric_monitor.update(\"Loss\", loss.item())\n#         metric_monitor.update(\"Accuracy\", accuracy)\n#         metric_monitor.update(\"Jaccard\", jaccard)\n#         metric_monitor.update(\"FBeta\", fbeta)\n        \n        train_loss += loss.detach().float()\n        lr = optimizer.param_groups[0]['lr']\n        _train_metrics = {\n            \"train/step_loss\": loss.item(),\n            \"learning_rate\": lr,\n#             \"train/accuracy\": accuracy,\n#             \"train/jaccard_index\": jaccard,\n#             \"train/fbeta_score\": fbeta\n        }\n        \n        if (i+1) % 50 == 0:\n            wandb.log(_train_metrics)\n            \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        \n        stream.set_description(\n            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n        )\n        \n    total_train_loss = train_loss / len(train_loader)\n    \n    gc.collect()\n    flush()\n    return _train_metrics, total_train_loss\n        \ndef validate(val_loader, model, criterion, epoch, params):\n    metric_monitor = MetricMonitor()\n    model.eval()\n    stream = tqdm(val_loader)\n    valid_loss = 0\n    \n    with torch.no_grad():\n        for i, batch in enumerate(stream, start=1):\n            outputs = shared_step(batch, criterion, params)\n            loss =  outputs['site_loss'] + outputs['severe_loss']\n            \n#             accuracy = METRICS['accuracy'](predictions, target)\n#             jaccard = METRICS['jaccard_index'](predictions, target)\n#             fbeta = METRICS['fbeta_score'](predictions, target)\n\n            metric_monitor.update(\"Loss\", loss.item())\n#             metric_monitor.update(\"Accuracy\", accuracy)\n#             metric_monitor.update(\"Jaccard\", jaccard)\n#             metric_monitor.update(\"FBeta\", fbeta)\n            \n            valid_loss += loss.detach().float()\n            _valid_metrics = {\n                \"valid/step_loss\": loss.item(),\n#                 \"valid/loss\": valid_loss,\n#                 \"valid/accuracy\": accuracy,\n#                 \"valid/jaccard_index\": jaccard,\n#                 \"valid/fbeta_score\": fbeta\n            }\n\n            if (i+1) % 10 == 0:\n                wandb.log(_valid_metrics)\n            \n            stream.set_description(\n                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n            )\n            \n#         if epoch%9 == 0:\n#             print(f\"##### Visualizing mini batches at epoch {epoch} ####\")\n#             visualize_mini_batches(batch, predictions)\n    gc.collect()\n    flush()\n    total_valid_loss = valid_loss / len(val_loader)\n    return _valid_metrics, total_valid_loss","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.235837Z","iopub.execute_input":"2024-05-26T03:33:02.236123Z","iopub.status.idle":"2024-05-26T03:33:02.254484Z","shell.execute_reply.started":"2024-05-26T03:33:02.236089Z","shell.execute_reply":"2024-05-26T03:33:02.253590Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def train_and_validate(model, train_dataset, val_dataset, params, fold=0):\n    model = model.to(params['device'])\n    run = wandb.init(\n        project=\"PlasticOpticsMultiClassification\", \n        resume=\"allow\"\n    )\n    \n    artifact = wandb.Artifact(f\"aerialMultiFPNModel_fold_{fold}\", type=\"model\")\n    \n    train_loader = get_dataloaders(train_data, cfg=CONFIG, split='train', multi=False)\n    val_loader = get_dataloaders(valid_data, cfg=CONFIG, split=\"valid\", multi=False)\n    \n    criterion = nn.CrossEntropyLoss().to(params[\"device\"])\n    optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\n    scaler = torch.cuda.amp.GradScaler()\n#     scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, \n#                                                                      params['epochs'], \n#                                                                      eta_min=0)\n    \n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=params['epochs'], eta_min=0)\n    lr_reduce = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=4, verbose=True)\n    best_metric = np.inf\n    loss_min = np.inf\n    es = 0\n    ES_RATIO = 0.25 if params['epochs'] < 10 else 0.20\n#     seg_weights_file = \"aerialwaste_fpn_weights.pth\"\n    weights_file = \"aerialwaste_multi_task_fold_{fold}_epoch_{epoch}.pth\"\n    for epoch in range(1, params[\"epochs\"] + 1):\n        scheduler.step()\n        _train_metrics, train_loss = train(train_loader, model, criterion, optimizer, epoch, scaler, params)\n        _valid_metrics, val_loss = validate(val_loader, model, criterion, epoch, params)\n        \n        _train_metrics[\"train/loss\"] = train_loss\n        _valid_metrics[\"valid/loss\"] = val_loss\n        lr_reduce.step(val_loss)\n        wandb.log({**_train_metrics, **_valid_metrics})\n        if val_loss < best_metric:\n            print(f\"Best metric: ({best_metric:.6f} --> {val_loss:.6f}). Saving model ...\")\n#             torch.save(model.module.state_dict(), f\"{name}_fold_{fold}.pth\")\n            weights_file.format(fold=fold, epoch=epoch)\n            torch.save(model.state_dict(), weights_file)\n            best_metric = val_loss\n            es = 0\n            if epoch == 1:\n                artifact.add_file(weights_file)\n                run.log_artifact(artifact)\n            else:\n                draft_artifact = wandb.Artifact(f\"aerialMultiFPNModel_fold_{fold}\", type=\"model\")\n                draft_artifact.add_file(weights_file)\n                run.log_artifact(draft_artifact)\n            \n        else:\n            es += 1\n            \n        if es > math.ceil(ES_RATIO*params['epochs']):\n            print(f\"Early stopping on epoch {epoch} ...\")\n            break\n            \n    wandb.config = params\n    wandb.finish()\n    flush()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.255668Z","iopub.execute_input":"2024-05-26T03:33:02.255967Z","iopub.status.idle":"2024-05-26T03:33:02.269809Z","shell.execute_reply.started":"2024-05-26T03:33:02.255943Z","shell.execute_reply":"2024-05-26T03:33:02.269001Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"kfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2024)\ntrain_df = train_df.sample(frac=1.0, random_state=2024)\nx = train_df.index.values\n# y = train_df['severity'].astype(int).values\ny = train_df['severity'].astype(int).values\ng = train_df['target_site'].astype(int).values\n\ntrain_df['fold'] = -1\nfor fold, (tr_idx, val_idx) in enumerate(kfold.split(x,y)):\n    train_df.loc[val_idx, 'fold'] = fold","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.270725Z","iopub.execute_input":"2024-05-26T03:33:02.270995Z","iopub.status.idle":"2024-05-26T03:33:02.292165Z","shell.execute_reply.started":"2024-05-26T03:33:02.270974Z","shell.execute_reply":"2024-05-26T03:33:02.291320Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"CONFIG['lr'] = 3e-4\nfor fold in range(5):\n    model = MultiResnetFPN(name='resnet34', site_classes=6, severe_classes=4, pretrained=True)\n    train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n    valid_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n    train_and_validate(model, train_data, valid_data, params=CONFIG, fold=fold)\n    \ngc.collect()\nflush()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T03:33:02.293262Z","iopub.execute_input":"2024-05-26T03:33:02.293581Z","iopub.status.idle":"2024-05-26T06:20:10.792524Z","shell.execute_reply.started":"2024-05-26T03:33:02.293552Z","shell.execute_reply":"2024-05-26T06:20:10.790541Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/87.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eecc73c6d684411ba789cdd20ffe86c"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamu2505\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240526_033304-euioifdb</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/euioifdb' target=\"_blank\">splendid-glitter-37</a></strong> to <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/euioifdb' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/euioifdb</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a80d03f890cc48f28a724c78e74cfd20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a934aefe6cc047008fd66c40e8404a52"}},"metadata":{}},{"name":"stdout","text":"Best metric: (inf --> 2.942984). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccfd17c222ce4534975efc3153b0f614"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b250c3a7c5954325823b7472e032b110"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.942984 --> 2.656048). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d560845373f7429891e0fb8a0199a2e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1b60009087846e7857583369b3ea6a4"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.656048 --> 2.464422). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0f26a0c150f42aaa07ba448a19958b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6796908ff4bf4e6c954b8d3b19ada9fc"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.464422 --> 2.425446). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"255d928d74a34975ac6b5453a08fb979"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28a1a93d7c2849378883e6d296090243"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.425446 --> 2.378098). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f65af2ee353c455383dec19778e1d1df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ebfef93d0b34320ab1c72d7fce7478b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc34c49dd1264348acd2d052e0f39295"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7de59b91d47c42959f1cafd6b143131a"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.378098 --> 2.375860). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47f77f015b7940e79c03895568e66291"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a4176f0a8d64ad79c009f166f509c2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"463cf12e921245ef84d8b5793f53d8e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dda56a3e26a2483891689232e6305179"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c45932136634692a6f7f0ed9d6c1772"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fd8bc7f468b4e9aa161268265d45715"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.375860 --> 2.343814). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2f702a2cec7454fb202f148514de533"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1fcc28cfbb8470d8b28bbb25251a6d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f5d4dbaf6dd461099dc723a368bc2b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"280016ae45d54e20b09b4e297ea4f125"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01e45cd922e74001acdf45ad64e0e86d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68a1151765b940b0b9d4c4cb1d68d1bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db20b40b00b840b4bde1ca21053614bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"154464052df34e5698ff111592360714"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f80a4b5359d34cd2a3143eb984487e53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75484e9280e5471f80467bd07f96ea2a"}},"metadata":{}},{"name":"stdout","text":"Epoch 00015: reducing learning rate of group 0 to 2.3817e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"584c507369854acbb1afcaa6af1dccb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2138f9cefcdd4fde831a95b11fcd4a3f"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.343814 --> 2.270952). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8300d6e84fce45c5ab9bd6150924a227"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90aa9b6bdcf4459fbe14c12029b5c67e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22d51cbef8f447c2aaa71ebf8ceedf09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"252f0be6788b45bb8522b4b068bfdda3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f133c201f8d24df7ac172eda7d6637d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61df5e061c8b4480af590730d5028e2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e280fe3b99d44ff93c68cb5dd91c59f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"552cdf23a8ad485786e90d1da8970d40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2141b955f36428ca123b42a4cdd01d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd24a845385e414aa34573de95dc4122"}},"metadata":{}},{"name":"stdout","text":"Epoch 00021: reducing learning rate of group 0 to 1.8730e-06.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"511f7aa0cb9c4c7caf80443b8f605c66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b56658e4d79c44a3850b3fb19b1f88a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"782fd6f6e6bd446b979cc36144d9f15f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea4e38d6cec34ed0bc8108a53ba6ce87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d236831a550441889204d9b647782295"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"495ff5a5b8304793811d9194a45725e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b53c7e6e9ffe4d1fb397f810e50a6478"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a67cc7f3f424874b6bb24cf770303be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"026558f4c64840f0a198453aacbb6d77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7aca36acac334091a9fe82579fef1e86"}},"metadata":{}},{"name":"stdout","text":"Epoch 00026: reducing learning rate of group 0 to 1.4058e-07.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e97637907254494180cb4ab14649e65e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e950acfab62e4211a0f901a9a147edb4"}},"metadata":{}},{"name":"stdout","text":"Early stopping on epoch 27 ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/step_loss</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/step_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.01014</td></tr><tr><td>train/step_loss</td><td>0.88342</td></tr><tr><td>valid/loss</td><td>2.31165</td></tr><tr><td>valid/step_loss</td><td>2.36457</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">splendid-glitter-37</strong> at: <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/euioifdb' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/euioifdb</a><br/> View project at: <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240526_033304-euioifdb/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240526_041709-kq1ca4c8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/kq1ca4c8' target=\"_blank\">whole-galaxy-38</a></strong> to <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/kq1ca4c8' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/kq1ca4c8</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"262fcda105d0438896863dc5a87fe9c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f865b7ec045a44c29adde28f865f12ac"}},"metadata":{}},{"name":"stdout","text":"Best metric: (inf --> 2.892582). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a137795f3f04be7a0057eb99b1d1ee5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7502c0b3ce154574ad427fa678f7191c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3f2c80be55d4b7392cfa1f28e9c7e8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ab1edeba8384caf92b952b9152c924f"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.892582 --> 2.777687). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"028d8f6d3e81406a909606d386675fcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e030b9246b4b44f3ac3c2b15e3bf8d7c"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.777687 --> 2.609022). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4098eb0257ec43a0b426a51c2a0f9e74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec6af6ccf9c8460a88f67d58ce5df1a3"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.609022 --> 2.584892). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b1b4e0e7a3c49d09e86f328a2632517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc75f072a3f643d2b17dfc939dfa6863"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.584892 --> 2.498288). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d26a5da61f44d03856ce7c5c8b528f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8191ce2ee0c940359b022c2594eed165"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ffc45fd51484c2dbe5207c6ccdd22d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e34d8795453d4bf7b3f8b22333a54b13"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.498288 --> 2.457701). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"554dbc11475f48eba1a68d68e008aeb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2947289be67140f2ae5459ca62d9c040"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd36dc4d1cc948069d2d943e6b71a64c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f919323736454c999e641352b9ce53a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"139d0959e83349c2836d30990e66faa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40490e4786dd4646bb6152170815bb5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4186d27dbc2d4e16b8f0d599a816ca37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbf1b11c6ae440b6b666919762baa888"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0e95186af964a8c9be925e368471f5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09ff05fa79724caabf86fd1606eecac5"}},"metadata":{}},{"name":"stdout","text":"Epoch 00013: reducing learning rate of group 0 to 2.5268e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb44c5ac7b7947c381e59c38b09eee89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc60176259f845ffa2998dd8705184c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"108087f2d7bb4e60b869abca05338585"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f91f493edac49a9acd5eeaca8fa0615"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccdaeb968ac84ab0816299e33852568b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f7f0514fee04bc682b94d8cb3da4919"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d05e1d68e0204b46afb69d7e16c4a517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12697c5cac4d429681aad59c2469dbe5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67c93a982c674f328c025b32e0298b7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53e5c579f9114557b81f7d757d13f85d"}},"metadata":{}},{"name":"stdout","text":"Epoch 00018: reducing learning rate of group 0 to 2.1387e-06.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8159661ffc3d4d738398ecdcd6d7b58b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"291ef46896604458a542c37731831a9a"}},"metadata":{}},{"name":"stdout","text":"Early stopping on epoch 19 ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='497.302 MB of 497.302 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/step_loss</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/step_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.22566</td></tr><tr><td>train/step_loss</td><td>0.99326</td></tr><tr><td>valid/loss</td><td>2.47053</td></tr><tr><td>valid/step_loss</td><td>2.67839</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">whole-galaxy-38</strong> at: <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/kq1ca4c8' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/kq1ca4c8</a><br/> View project at: <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification</a><br/>Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240526_041709-kq1ca4c8/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240526_044803-ts4cudkm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/ts4cudkm' target=\"_blank\">polar-bee-39</a></strong> to <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/ts4cudkm' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/ts4cudkm</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"779f6da98856464485597f3a565ddad5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5457c221fad0439ea971771ead006ca7"}},"metadata":{}},{"name":"stdout","text":"Best metric: (inf --> 2.795638). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efd1a7ccb17a4ed2aba9967acd31a96a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e03315ef498e43d695749bf1041a17ec"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.795638 --> 2.690984). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b16d6beaa25243d38e4e17623ea2197b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12d64e81341941dfaf448f0f716e470c"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.690984 --> 2.604726). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f485cf087b84f5e9a7e917c71125983"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ce77e908aca4dadbdbe7b91f39d9e52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ac9259026d6464c89facece9f842b57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9b1c0e941b84a9d990c7d7033a51cb7"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.604726 --> 2.486273). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f713c19e840a4525ae2e4fe2533c2bb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49dac133abb94267bf628ef72a599ad4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20ed74d5ce1c4374a0f23f0052dd4f04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79e0a13687854c298bf85b9cefa6805e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3fef61d4b5c43a8a6e54cc3dafe6476"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c24720941d614634b473c6763bcc60ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d03db0148774e40861f34e4cfc973ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc18958a428d43fbae0a3a718ebf8628"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6928591e99c412ba2871757e7d99d0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f887af09b8846999c24d315c5d079fb"}},"metadata":{}},{"name":"stdout","text":"Epoch 00010: reducing learning rate of group 0 to 2.7135e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8140b407e9464e4fb5139fe2740a1862"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24183ed36164472c9041b5a7821431e7"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.486273 --> 2.480856). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8708e261fbdf413d99b8ce544d4d5a70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9fd1f3740734deda91ec36d8615ad2c"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.480856 --> 2.463279). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a29b2cc96ee542b5a935f624ed70e77f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f74309985ee245ea9812b76dec9e7f38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13c49fc9c7f640f59bdd03a2b3e26ee6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e655cc5dff14f2c8275c5f3c5ba8d4f"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.463279 --> 2.442024). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f54f381a55024f0a915f0c18565fa428"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b98fe438c78a4cd2aaf51d1b130c4cab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a7ee2e360f742e9af4f2bd78acaa724"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04fa5035004945fc93f2f32cd0d83fd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84643fd0519846c0afec859e52fb451a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b43e7f8f7de54602bf9f9829e9391435"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e51eabb9f5644ef78d7f3e1009f5e013"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f79ba565a8914879aadd3761c35cad3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ef32e0d2b274da4b85a9f722ef12143"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"030a66427eb94893827d3dba3b066f37"}},"metadata":{}},{"name":"stdout","text":"Epoch 00019: reducing learning rate of group 0 to 2.0522e-06.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0d650ca2d044fd0917a38d78c4a5450"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c27ffcde55c443cb712f0b11c624f13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ada7fe1143b46a3a9ae6075101833b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75d44e578f56414fb81e9b54c12b762b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"309cead97e714cc5b95d74ee08c4921b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"747b6da8484a44f69b8a19a81b49653b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf51248cf354084b54135ce4567b044"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1c4efe09d254632a1557b04a8048125"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98d60a0509f84538bae73e16ddff9074"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4afd3a6134b4034a113569dfa791f4e"}},"metadata":{}},{"name":"stdout","text":"Epoch 00024: reducing learning rate of group 0 to 1.5942e-07.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d438fb3cd01d4877b0a5745cc75a6a12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0814dee04fe7404fa706187d22e1cdb6"}},"metadata":{}},{"name":"stdout","text":"Early stopping on epoch 25 ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='580.185 MB of 580.185 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/step_loss</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/step_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.17186</td></tr><tr><td>train/step_loss</td><td>1.27458</td></tr><tr><td>valid/loss</td><td>2.46436</td></tr><tr><td>valid/step_loss</td><td>2.63649</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">polar-bee-39</strong> at: <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/ts4cudkm' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/ts4cudkm</a><br/> View project at: <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240526_044803-ts4cudkm/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240526_052836-upk5alga</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/upk5alga' target=\"_blank\">volcanic-totem-40</a></strong> to <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/upk5alga' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/upk5alga</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b0e2398185d4eb19c4592c351409bea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1f16e718314fe0b82ddcf57034a51a"}},"metadata":{}},{"name":"stdout","text":"Best metric: (inf --> 2.933050). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5a36d87de884fbb948fbfd1f5e84532"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e83fd5757c144a859eb7dacdb5f3d6bd"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.933050 --> 2.683589). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0b5f563d73f4bc0b65503ed925df421"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd916b52eaa34c3b853a939a03ed65e6"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.683589 --> 2.605495). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a201d3ff1124319a748d03dd9eb57f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"097a45a22c4843c9a98c290b9b315d52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cdecf0bc69247ba9ca98617832d4ddc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"675daff6f156421992c2e0767aeaf73e"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.605495 --> 2.508903). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bbb67b04f4a4f31a8e7e50f62673151"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2de0e0edd389425aa989172a52565a50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3469d002b83490f846a6d831c253796"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5000519649e94d268d0108c01103251d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21ffa967b1f4488f8826a5ea52219f3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40d509a8bc5049fcbec7869987fb561c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68fa7c4e2daf464e995978d9d90691dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"850bf76d2b534225b51d68115fb6b206"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9e0398a268443f6ab42ee95eb9c73d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"017772c3bfad46f083d1960d96834fbe"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.508903 --> 2.373917). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4aed8e8228454fd9aa3b0394fb8e1711"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a45930ac9a44fc89b7fea1d4d511335"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b04f33259e046d1976cccd9418f7ec6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff051717b6904a08a763cc41ea086089"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"912518d4a7824754b4aece7c18ec681d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16b99aab068c453bac2a70e5775b6667"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfe16a9fd3e9450f965d1abd78648313"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc6e5c0640a049b9bcbae3d5dc474b5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2523181190494eb9bdc492e3bc1c2532"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bac8812d02384ad8b70a57632d6198a1"}},"metadata":{}},{"name":"stdout","text":"Epoch 00015: reducing learning rate of group 0 to 2.3817e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eef40423a3e24ed082712a1adc23eb8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"235c6b8e24fc4209957d645c0a73b506"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.373917 --> 2.367036). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"251f38926b2c48668083c841b879524a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d605a53b8f5c4b8892b397018fcf9a16"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.367036 --> 2.355025). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0113df5e9ca74de59bf6a52c0d420adb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9beb55a2ed4447738a8ca99fb232411a"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.355025 --> 2.336689). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e87aae1560304dc4aac99f75595cd048"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e39397dd9d944c1681ec98f28811a697"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.336689 --> 2.334118). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e71f3f68c3af4d8985a8871bcd3566d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e010e28d89bd4ba98288f0e041e86346"}},"metadata":{}},{"name":"stdout","text":"Best metric: (2.334118 --> 2.326448). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"681eed690d0c43dd87d4c86779e6cf23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be35556c0c7d4252a951e71e3ec74194"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75a4fcd1dad5433f984f7a23e7d30fb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4a23efcfd8f4a609473ade34fa1033f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b3ceea443c24b56b01cdb933be87cf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8afb9c61c374b4ebde035c18e0f7cb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6de6efeb7ca540768651357e39942def"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e453dfb6c73d4f038f388dc0450e70b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca51a06694de4964b82d75b61da99419"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a65d53ee793f4928bc67b785a6f74dca"}},"metadata":{}},{"name":"stdout","text":"Epoch 00025: reducing learning rate of group 0 to 1.5000e-06.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06433e91586b4b32b19e5bf6d0f1f6d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8c4b92fb65e4de5888de065804a30ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"466e7fb5482e4007ab29b5e28e3afd52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eaffdc7ecf649d19568685e11f812c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29200a03b468461c8c545f098a0d45ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0f6dd4181cd4385adf4fbe631a4e634"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5589992a5c4f49ba9a9a7315cbffbd29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f14a0e830bff49899bc12e69a598d846"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6130ff9c2b534d60a8db9ec795f0705d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da55b2191f26431baa055231fef498dc"}},"metadata":{}},{"name":"stdout","text":"Epoch 00030: reducing learning rate of group 0 to 1.0365e-07.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28ebe1f836d84bb39efa607b604dcc3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc89ffd932fb4131b7e1af3e0a39aca3"}},"metadata":{}},{"name":"stdout","text":"Early stopping on epoch 31 ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='828.835 MB of 828.835 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/step_loss</td><td></td></tr><tr><td>valid/loss</td><td></td></tr><tr><td>valid/step_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.25293</td></tr><tr><td>train/step_loss</td><td>1.06588</td></tr><tr><td>valid/loss</td><td>2.34845</td></tr><tr><td>valid/step_loss</td><td>1.84714</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">volcanic-totem-40</strong> at: <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/upk5alga' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/upk5alga</a><br/> View project at: <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification</a><br/>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240526_052836-upk5alga/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240526_061840-mkvtnkzk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/mkvtnkzk' target=\"_blank\">copper-glade-41</a></strong> to <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/mkvtnkzk' target=\"_blank\">https://wandb.ai/samu2505/PlasticOpticsMultiClassification/runs/mkvtnkzk</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"070f1b382fa34a5fb114b8f038ab9153"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7a8e56caeed485b97b1cef5e3bb62b3"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7af669310940>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n    self._shutdown_workers()\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 149, in join\n    res = self._popen.wait(timeout)\n  File \"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n    if not wait([self.sentinel], timeout):\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n    ready = selector.select(timeout)\n  File \"/opt/conda/lib/python3.10/selectors.py\", line 416, in select\n    fd_event_list = self._selector.poll(timeout)\nKeyboardInterrupt: \n","output_type":"stream"},{"name":"stdout","text":"Best metric: (inf --> 2.959573). Saving model ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb99b6736579406e811b30893240f94a"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     train_data \u001b[38;5;241m=\u001b[39m train_df[train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m fold]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     valid_data \u001b[38;5;241m=\u001b[39m train_df[train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m fold]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      9\u001b[0m flush()\n","Cell \u001b[0;32mIn[30], line 30\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, train_dataset, val_dataset, params, fold)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     29\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 30\u001b[0m     _train_metrics, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     _valid_metrics, val_loss \u001b[38;5;241m=\u001b[39m validate(val_loader, model, criterion, epoch, params)\n\u001b[1;32m     33\u001b[0m     _train_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/loss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_loss\n","Cell \u001b[0;32mIn[29], line 57\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, scaler, params)\u001b[0m\n\u001b[1;32m     54\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog(_train_metrics)\n\u001b[1;32m     56\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 57\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     60\u001b[0m stream\u001b[38;5;241m.\u001b[39mset_description(\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{epoch}\u001b[39;00m\u001b[38;5;124m. Train.      \u001b[39m\u001b[38;5;132;01m{metric_monitor}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m=\u001b[39mepoch, metric_monitor\u001b[38;5;241m=\u001b[39mmetric_monitor)\n\u001b[1;32m     62\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:416\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    414\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 416\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:314\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    315\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:314\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    315\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# batch = next(iter(dls))\n# model = MultiResnetFPN(name='resnet18', site_classes=6, severe_classes=4)\n# model.eval()\n# site, severe = model(batch['image'])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:20:10.793900Z","iopub.status.idle":"2024-05-26T06:20:10.794401Z","shell.execute_reply.started":"2024-05-26T06:20:10.794148Z","shell.execute_reply":"2024-05-26T06:20:10.794170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# criterion = AsymmetricLossOptimized()\n# criterion(batch['site'], site), criterion(batch['severity'], severe)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:20:10.795548Z","iopub.status.idle":"2024-05-26T06:20:10.795939Z","shell.execute_reply.started":"2024-05-26T06:20:10.795759Z","shell.execute_reply":"2024-05-26T06:20:10.795777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class MultiFPNModel(pl.LightningModule):\n#     def __init__(self, name, site_classes, severe_classes, pretrained=False, lr=1e-3):\n#         super().__init__()\n#         self.save_hyperparameters()\n#         self.model = MultiResnetFPN(name=name, \n#                                     site_classes=site_classes, \n#                                     severe_classes=severe_classes, \n#                                     pretrained=pretrained)\n#         self.loss_fn = nn.CrossEntropyLoss()\n# #         self.loss_fn = AsymmetricLossOptimized()\n#         self.step_outputs = []\n#         self.site_acc = torchmetrics.Accuracy(num_classes=site_classes, task=\"multiclass\", average=\"micro\")\n#         self.severe_acc = torchmetrics.Accuracy(num_classes=severe_classes, task=\"multiclass\", average=\"micro\")\n        \n#     def forward(self, x):\n#         return self.model(x)\n    \n#     def shared_step(self, batch, stage):\n#         image, severe, site = batch[\"image\"], batch[\"severity\"], batch[\"site\"]\n#         site_logits, severe_logits = self.forward(image.to(torch.float32))\n# #         loss_site = self.loss_fn(site, site_logits)\n#         loss_site = self.loss_fn(site_logits, site.to(torch.int64))\n#         prob_site = F.softmax(site_logits, dim=-1)\n#         pred_site = torch.argmax(prob_site, dim=-1)\n        \n# #         loss_severe = self.loss_fn(severe, severe_logits)\n#         loss_severe = self.loss_fn(severe_logits, severe.to(torch.int64))\n#         prob_severe = F.softmax(severe_logits, dim=-1)\n#         pred_severe = torch.argmax(prob_severe, dim=-1)\n        \n#         total_loss = loss_site + loss_severe\n        \n#         site_acc = self.site_acc(pred_site, site)\n#         severe_acc = self.severe_acc(pred_severe, severe)\n#         self.log(f\"{stage}_site_loss\", loss_site, on_step=False, on_epoch=True, prog_bar=True)\n#         self.log(f\"{stage}_severe_loss\", loss_severe, on_step=False, on_epoch=True, prog_bar=True)\n#         self.log(f\"{stage}_loss\", total_loss, on_step=True, on_epoch=True, prog_bar=True)\n#         self.log(f\"{stage}_site_acc\", site_acc, on_step=False, on_epoch=True, prog_bar=False)\n#         self.log(f\"{stage}_severe_acc\", severe_acc, on_step=False, on_epoch=True, prog_bar=False)\n        \n#         output = {\n#             f\"{stage}_loss\": total_loss,\n#             f\"{stage}_site_acc\": site_acc,\n#             f\"{stage}_severe_acc\": severe_acc,\n#         }\n# #         self.step_outputs.append(output)\n#         return output\n    \n#     def training_step(self, batch, batch_idx):\n#         outputs = self.shared_step(batch, \"train\")\n#         return outputs['train_loss']\n    \n#     def validation_step(self, batch, batch_idx):\n#         self.eval()\n#         return self.shared_step(batch, \"valid\")\n        \n#     def test_step(self, batch, batch_idx):\n#         return self.shared_step(batch, \"test\")  \n    \n#     def configure_optimizers(self):\n#         max_epochs = self.trainer.max_epochs\n#         optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n# #         scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n#         cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs, eta_min=0.0)\n#         plateau_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n#                                                                        factor=0.1, patience=10, \n#                                                                        threshold=0.0001, cooldown=0, \n#                                                                        min_lr=0, eps=1e-08, verbose=True)\n# #         scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n# #             optimizer, T_0=10, T_mult=2)\n#         scheduler = {\n#             'scheduler': torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.trainer.max_epochs, eta_min=0),\n#             'interval': 'epoch',\n#             'frequency': 1,\n#             'monitor': 'val_loss',  # Make sure to replace 'val_loss' with your actual validation metric\n#         }\n#         scheduler_plateau = {\n#             'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10),\n#             'interval': 'epoch',\n#             'frequency': 1,\n#             'monitor': 'valid_loss',  # Make sure to replace 'val_loss' with your actual validation metric\n#             'strict': True,\n#         }\n#         return [optimizer], [scheduler, scheduler_plateau]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:20:10.797616Z","iopub.status.idle":"2024-05-26T06:20:10.797947Z","shell.execute_reply.started":"2024-05-26T06:20:10.797787Z","shell.execute_reply":"2024-05-26T06:20:10.797801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2024)\n# train_df = train_df.sample(frac=1.0, random_state=2024)\n# x = train_df.index.values\n# # y = train_df['severity'].astype(int).values\n# y = train_df['severity'].astype(int).values\n# g = train_df['target_site'].astype(int).values\n\n# train_df['fold'] = -1\n# for fold, (tr_idx, val_idx) in enumerate(kfold.split(x,y)):\n#     train_df.loc[val_idx, 'fold'] = fold","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:20:10.800500Z","iopub.status.idle":"2024-05-26T06:20:10.800929Z","shell.execute_reply.started":"2024-05-26T06:20:10.800716Z","shell.execute_reply":"2024-05-26T06:20:10.800734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONFIG['patience'] = 8 if CONFIG['epochs'] < 50 else 12\n# for fold in range(5):\n#     train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n#     valid_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n#     train_dls = get_dataloaders(train_data, cfg=CONFIG, split='train', multi=False)\n#     valid_dls = get_dataloaders(valid_data, cfg=CONFIG, split=\"valid\", multi=False)\n\n#     net = MultiFPNModel(name='resnet50', \n#                         site_classes=6, \n#                         severe_classes=4, \n#                         pretrained=True, lr=1e-4)\n\n#     wandb_logger = WandbLogger(project=\"Plastic-Optics-multi-classification-FPN\",\n#                                checkpoint_name=f\"aerialMultiFPNModel_fold_{fold}\", \n#                                log_model=\"all\")\n\n#     callbacks = [\n#         ModelCheckpoint(save_weights_only=True, \n#                         mode=\"min\", \n#                         monitor=\"valid_loss\"),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n#         LearningRateMonitor(\"epoch\"),\n#         EarlyStopping(monitor=\"valid_loss\", min_delta=0.0, patience=CONFIG['patience'], verbose=False, mode=\"min\"),\n#     ]\n#     # trainer = pl.Trainer(fast_dev_run=100)\n#     trainer = pl.Trainer(max_epochs=CONFIG['epochs'], logger=wandb_logger, callbacks=callbacks)\n#     trainer.fit(net, train_dataloaders=train_dls, val_dataloaders=valid_dls)\n    \n#     break\n# wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:20:10.802245Z","iopub.status.idle":"2024-05-26T06:20:10.802577Z","shell.execute_reply.started":"2024-05-26T06:20:10.802416Z","shell.execute_reply":"2024-05-26T06:20:10.802430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = MultiFPNModel(name='resnet18', site_classes=6, severe_classes=4)\n# trainer = pl.Trainer(max_epochs=10)\n# trainer.fit(model, train_dataloaders=dls)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:20:10.803880Z","iopub.status.idle":"2024-05-26T06:20:10.804237Z","shell.execute_reply.started":"2024-05-26T06:20:10.804046Z","shell.execute_reply":"2024-05-26T06:20:10.804060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(model.state_dict(), 'aerial_multi.pth')","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:20:10.805631Z","iopub.status.idle":"2024-05-26T06:20:10.805939Z","shell.execute_reply.started":"2024-05-26T06:20:10.805788Z","shell.execute_reply":"2024-05-26T06:20:10.805801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Efficient Net Model","metadata":{}},{"cell_type":"code","source":"# class AerialLightningModel(pl.LightningModule):\n#     def __init__(self, \n#                  name: str, \n#                  site_classes: int = 0, \n#                  severity_classes: int = 0, \n# #                  evidence_classes: int = 0, \n#                  pretrained: bool = False, \n#                  kernel_size: int = 3, \n#                  stride: int = 2, \n#                  lr: float = 3e-4):\n        \n#         super().__init__()\n#         self.save_hyperparameters()\n#         self.encoder = timm.create_model(name, pretrained=pretrained, num_classes=0)\n#         nb_fts = self.encoder.num_features\n#         nb_fts = nb_fts // stride\n#         self.nb_fts = nb_fts if kernel_size < 3 else nb_fts - 1\n#         self.avg_pool = nn.AvgPool1d(kernel_size, stride=stride)\n        \n#         self.flatten = nn.Flatten()\n#         self.site_head = nn.Sequential(\n#             nn.Dropout(0.2),\n#             nn.Linear(self.nb_fts, 384),\n#             nn.ReLU(),\n# #             nn.BatchNorm1d(768),\n#             nn.Dropout(0.2),\n#             nn.Linear(384, 4*site_classes),\n#             nn.ReLU(),\n# #             nn.BatchNorm1d(256),\n#             nn.Dropout(0.2),\n#             nn.Linear(4*site_classes, site_classes)\n#         )\n        \n#         self.severe_head = nn.Sequential(\n#             nn.Dropout(0.2),\n#             nn.Linear(self.nb_fts, 384),\n#             nn.ReLU(),\n# #             nn.BatchNorm1d(768),\n#             nn.Dropout(0.2),\n#             nn.Linear(384, 4*severity_classes),\n#             nn.ReLU(),\n# #             nn.BatchNorm1d(256),\n#             nn.Dropout(0.2),\n#             nn.Linear(4*severity_classes, severity_classes)\n#         )\n\n        \n#         self.loss_function = nn.CrossEntropyLoss()\n#         self.step_outputs = []\n#         self.site_acc = torchmetrics.Accuracy(num_classes=site_classes, task=\"multiclass\", average=\"micro\")\n#         self.severe_acc = torchmetrics.Accuracy(num_classes=severity_classes, task=\"multiclass\", average=\"micro\")\n        \n        \n#     def forward(self, x):\n#         x = self.encoder(x)\n#         x = self.flatten(x)\n#         x = self.avg_pool(x)\n        \n#         site_outputs = self.site_head(x)\n#         severe_outputs = self.severe_head(x)\n#         return site_outputs, severe_outputs\n    \n#     def shared_step(self, batch, stage):\n#         image, severe, site = batch[\"image\"], batch[\"severity\"], batch[\"site\"]\n#         site_logits, severe_logits = self.forward(image.to(torch.float32))\n        \n#         loss_site = self.loss_function(site_logits, site.to(torch.int64))\n#         prob_site = F.softmax(site_logits, dim=-1)\n#         pred_site = torch.argmax(prob_site, dim=-1)\n        \n#         loss_severe = self.loss_function(severe_logits, severe.to(torch.int64))\n#         prob_severe = F.softmax(severe_logits, dim=-1)\n#         pred_severe = torch.argmax(prob_severe, dim=-1)\n        \n#         total_loss = loss_site + loss_severe\n#         site_acc = self.site_acc(pred_site, site)\n#         severe_acc = self.severe_acc(pred_severe, severe)\n#         self.log(f\"{stage}_site_loss\", loss_site, on_step=False, on_epoch=True, prog_bar=True)\n#         self.log(f\"{stage}_severe_loss\", loss_severe, on_step=False, on_epoch=True, prog_bar=True)\n#         self.log(f\"{stage}_loss\", total_loss, on_step=True, on_epoch=True, prog_bar=True)\n#         self.log(f\"{stage}_site_acc\", site_acc, on_step=False, on_epoch=True, prog_bar=False)\n#         self.log(f\"{stage}_severe_acc\", severe_acc, on_step=False, on_epoch=True, prog_bar=False)\n        \n#         output = {\n#             f\"{stage}_loss\": total_loss,\n#             f\"{stage}_site_acc\": site_acc,\n#             f\"{stage}_severe_acc\": severe_acc,\n#         }\n#         self.step_outputs.append(output)\n#         return output\n    \n#     def training_step(self, batch, batch_idx):\n#         outputs = self.shared_step(batch, \"train\")\n#         return outputs['train_loss']\n    \n#     def validation_step(self, batch, batch_idx):\n#         self.eval()\n#         return self.shared_step(batch, \"valid\")\n        \n#     def test_step(self, batch, batch_idx):\n#         return self.shared_step(batch, \"test\")  \n    \n#     def configure_optimizers(self):\n#         max_epochs = self.trainer.max_epochs\n#         optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n# #         scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n#         cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs, eta_min=0.0)\n#         plateau_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n#                                                                        factor=0.1, patience=10, \n#                                                                        threshold=0.0001, cooldown=0, \n#                                                                        min_lr=0, eps=1e-08, verbose=True)\n# #         scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n# #             optimizer, T_0=10, T_mult=2)\n#         scheduler = {\n#             'scheduler': torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.trainer.max_epochs, eta_min=0),\n#             'interval': 'epoch',\n#             'frequency': 1,\n#             'monitor': 'val_loss',  # Make sure to replace 'val_loss' with your actual validation metric\n#         }\n#         scheduler_plateau = {\n#             'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10),\n#             'interval': 'epoch',\n#             'frequency': 1,\n#             'monitor': 'valid_loss',  # Make sure to replace 'val_loss' with your actual validation metric\n#             'strict': True,\n#         }\n#         return [optimizer], [scheduler, scheduler_plateau]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:20:10.807333Z","iopub.status.idle":"2024-05-26T06:20:10.807662Z","shell.execute_reply.started":"2024-05-26T06:20:10.807501Z","shell.execute_reply":"2024-05-26T06:20:10.807515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2024)\n# train_df = train_df.sample(frac=1.0, random_state=2024)\n# x = train_df.index.values\n# # y = train_df['severity'].astype(int).values\n# y = train_df['severity'].astype(int).values\n# g = train_df['target_site'].astype(int).values\n\n# train_df['fold'] = -1\n# for fold, (tr_idx, val_idx) in enumerate(kfold.split(x,y)):\n#     train_df.loc[val_idx, 'fold'] = fold\n    \n# # train_df['fold'].value_counts()\n# # train_df.groupby(['fold'])[['site_type', 'evidence', 'severity']].value_counts().reset_index()\n\n# # train_data = train_df[train_df['fold'].isin([0,1,3,4])].reset_index(drop=True)\n# # valid_data = train_df[~train_df['fold'].isin([0,1,3,4])].reset_index(drop=True)\n# # train_data.shape, valid_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:20:10.809193Z","iopub.status.idle":"2024-05-26T06:20:10.809527Z","shell.execute_reply.started":"2024-05-26T06:20:10.809367Z","shell.execute_reply":"2024-05-26T06:20:10.809380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONFIG['patience'] = 8 if CONFIG['epochs'] < 50 else 12\n# for fold in range(5):\n#     train_data = train_df[train_df['fold'] != fold].reset_index(drop=True)\n#     valid_data = train_df[train_df['fold'] == fold].reset_index(drop=True)\n#     train_dls = get_dataloaders(train_data, cfg=CONFIG, split='train')\n#     valid_dls = get_dataloaders(valid_data, cfg=CONFIG, split=\"valid\")\n\n#     net = AerialLightningModel(name='efficientnet_b3.ra2_in1k', \n#                                site_classes=6, \n#                                severity_classes=4, \n#     #                            evidence_classes=4, \n#                                pretrained=True, lr=2e-5)\n\n#     wandb_logger = WandbLogger(project=\"Plastic-Optics-multi-classification\",\n#                                checkpoint_name=f\"aerialMultiModel_fold_{fold}\", \n#                                log_model=\"all\")\n\n#     callbacks = [\n#         ModelCheckpoint(save_weights_only=True, \n#                         mode=\"min\", \n#                         monitor=\"valid_loss\"),\n#         LearningRateMonitor(\"epoch\"),\n#         EarlyStopping(monitor=\"valid_loss\", \n#                       min_delta=0.0, patience=CONFIG['patience'], \n#                       verbose=False, mode=\"min\"),\n#     ]\n#     # trainer = pl.Trainer(fast_dev_run=100)\n#     trainer = pl.Trainer(max_epochs=CONFIG['epochs'], \n#                          logger=wandb_logger, callbacks=callbacks)\n#     trainer.fit(net, train_dataloaders=train_dls, val_dataloaders=valid_dls)\n    \n#     break\n# wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:20:10.810652Z","iopub.status.idle":"2024-05-26T06:20:10.810991Z","shell.execute_reply.started":"2024-05-26T06:20:10.810831Z","shell.execute_reply":"2024-05-26T06:20:10.810846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# timm.list_pretrained(\"efficientnet*\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:20:10.812646Z","iopub.status.idle":"2024-05-26T06:20:10.812958Z","shell.execute_reply.started":"2024-05-26T06:20:10.812804Z","shell.execute_reply":"2024-05-26T06:20:10.812817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```python\nThe class distribution across the batches you've provided shows variability, which is expected in real-world datasets. However, if your goal is to achieve more balanced batches, especially for training a model where class imbalance could be an issue, you might consider the following steps:\n\n1. **Review Sampler**: Ensure you're using a sampler that promotes class balance, such as `WeightedRandomSampler` or `ImbalancedDatasetSampler`. These samplers can help in creating batches with a more even class distribution.\n\n2. **Adjust Batch Size**: If feasible, adjust the batch size. A smaller batch size might help in getting a more uniform distribution of classes, although it could also increase training time.\n\n3. **Custom Batch Creation**: Create a custom batch creation loop that manually ensures each batch has a balanced class distribution. This might involve more complex data handling but can provide you with the exact distribution you need.\n\n4. **Post-Processing**: After each batch is created, you could potentially swap out samples from over-represented classes with those from under-represented classes to balance the batch. This would require additional logic in your data loading process.\n\n5. **Data Augmentation**: For under-represented classes, consider using data augmentation techniques to increase the number of samples, which can then be used to create more balanced batches.\n\n6. **Analysis and Reporting**: If the class distribution is critical for your analysis, consider reporting the distribution as part of your model's performance metrics. This can provide insight into how well the model might perform on an imbalanced dataset.\n\nIf you're satisfied with the current distribution and it's not causing issues with model training, you may not need to take any action. However, if you're observing that the model's performance is being negatively impacted by the imbalance, then implementing one or more of the above strategies could be beneficial.\n\nWould you like to explore any of these options in more detail or need assistance with another aspect of your project? \n```","metadata":{}},{"cell_type":"markdown","source":"```python\nFor validation purposes, it's not strictly necessary for the batches to be balanced. The primary goal of validation is to assess the model's performance on a dataset that represents the real-world distribution of classes. Therefore, the validation set should ideally reflect the true class distribution you expect the model to encounter in practice.\n\nBalancing the validation batches could potentially skew the performance metrics and give an unrealistic picture of how the model would perform on naturally imbalanced data. It's important for the validation process to provide a clear indication of the model's ability to generalize to new, unseen data.\n\nHowever, if your validation set is extremely imbalanced, it might be difficult for the model to adequately learn the characteristics of the minority class. In such cases, you might consider using techniques like stratified sampling to ensure that all classes are represented in the validation set.\n\nIn summary, while training batches benefit from being balanced to prevent the model from being biased towards the majority class, validation batches should maintain the original data distribution to accurately evaluate the model's performance.\n\nIf you have any more questions or need further assistance, feel free to ask! \n```","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# from collections import Counter\n\n# def check_class_distribution(data_loader):\n#     batch_distributions = []\n#     for i, batch in enumerate(tqdm(data_loader)):\n#         labels = batch['severity']\n#         class_distribution = Counter(labels.numpy())\n#         batch_distributions.append({'Batch': i+1, 'Class Distribution': class_distribution})\n    \n#     # Convert to DataFrame\n#     df = pd.DataFrame(batch_distributions)\n    \n#     # Expand the 'Class Distribution' column into separate columns\n#     class_distributions = df['Class Distribution'].apply(pd.Series)\n#     df = pd.concat([df.drop(['Class Distribution'], axis=1), class_distributions], axis=1).fillna(0).astype(int)\n    \n#     return df\n\n# # Assuming `train_loader` is your DataLoader\n# df = check_class_distribution(train_dls)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:20:10.813743Z","iopub.status.idle":"2024-05-26T06:20:10.814069Z","shell.execute_reply.started":"2024-05-26T06:20:10.813909Z","shell.execute_reply":"2024-05-26T06:20:10.813923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df","metadata":{"execution":{"iopub.status.busy":"2024-05-26T06:20:10.815836Z","iopub.status.idle":"2024-05-26T06:20:10.816166Z","shell.execute_reply.started":"2024-05-26T06:20:10.815988Z","shell.execute_reply":"2024-05-26T06:20:10.816000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}